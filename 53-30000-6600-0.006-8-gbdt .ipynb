{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b1b438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de4e6563bbc54e39aa874ebe383879e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1080 [00:17<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "--------------------------------------------------\n",
      "Training fold 0 with 1365 features...\n",
      "[LightGBM] [Info] Number of positive: 103974, number of negative: 297574\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.921222 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224139\n",
      "[LightGBM] [Info] Number of data points in the train set: 401548, number of used features: 1357\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258933 -> initscore=-1.051522\n",
      "[LightGBM] [Info] Start training from score -1.051522\n",
      "Training until validation scores don't improve for 6000 rounds\n",
      "Early stopping, longdistance iteration is:\n",
      "[1]\t1\t0.708139756407846\t0.7259334885889446\n",
      "Early stopping, longdistance iteration is:\n",
      "[3]\t9\t0.746945968060753\t0.7477917327210519\n",
      "Early stopping, longdistance iteration is:\n",
      "[4]\t19\t0.7548494652068276\t0.7553835327086386\n",
      "Early stopping, longdistance iteration is:\n",
      "[6]\t39\t0.7591945278506098\t0.7592331312951293\n",
      "[100]\tvalid_0's binary_logloss: 0.378022\tvalid_0's amex_metric: 0.765478\n",
      "Early stopping, longdistance iteration is:\n",
      "[13]\t114\t0.7658882006999757\t0.7659057063299743\n",
      "[200]\tvalid_0's binary_logloss: 0.301224\tvalid_0's amex_metric: 0.772063\n",
      "Early stopping, longdistance iteration is:\n",
      "[14]\t256\t0.7743112612458354\t0.7743827226836991\n",
      "[300]\tvalid_0's binary_logloss: 0.26431\tvalid_0's amex_metric: 0.77612\n",
      "Early stopping, longdistance iteration is:\n",
      "[16]\t395\t0.7790277042566697\t0.7790360848303637\n",
      "[400]\tvalid_0's binary_logloss: 0.244867\tvalid_0's amex_metric: 0.778908\n",
      "[500]\tvalid_0's binary_logloss: 0.234028\tvalid_0's amex_metric: 0.783007\n",
      "[600]\tvalid_0's binary_logloss: 0.227649\tvalid_0's amex_metric: 0.787032\n",
      "Early stopping, longdistance iteration is:\n",
      "[17]\t615\t0.7871932897185663\t0.7872511838521605\n",
      "Early stopping, longdistance iteration is:\n",
      "[27]\t660\t0.7881748687882917\t0.7881993315348419\n",
      "[700]\tvalid_0's binary_logloss: 0.22364\tvalid_0's amex_metric: 0.789102\n",
      "[800]\tvalid_0's binary_logloss: 0.220956\tvalid_0's amex_metric: 0.792148\n",
      "Early stopping, longdistance iteration is:\n",
      "[30]\t850\t0.7925553411909991\t0.7925570149205727\n",
      "[900]\tvalid_0's binary_logloss: 0.219054\tvalid_0's amex_metric: 0.793438\n",
      "Early stopping, longdistance iteration is:\n",
      "[34]\t910\t0.7937461741123377\t0.7938836477882711\n",
      "[1000]\tvalid_0's binary_logloss: 0.217689\tvalid_0's amex_metric: 0.795039\n",
      "[1100]\tvalid_0's binary_logloss: 0.216601\tvalid_0's amex_metric: 0.794775\n",
      "Early stopping, longdistance iteration is:\n",
      "[128]\t1118\t0.7951430869472769\t0.7951948882807969\n",
      "[1200]\tvalid_0's binary_logloss: 0.215725\tvalid_0's amex_metric: 0.796382\n",
      "[1300]\tvalid_0's binary_logloss: 0.215043\tvalid_0's amex_metric: 0.79706\n",
      "[1400]\tvalid_0's binary_logloss: 0.214502\tvalid_0's amex_metric: 0.797664\n",
      "[1500]\tvalid_0's binary_logloss: 0.214047\tvalid_0's amex_metric: 0.797672\n",
      "[1600]\tvalid_0's binary_logloss: 0.213646\tvalid_0's amex_metric: 0.799109\n",
      "[1700]\tvalid_0's binary_logloss: 0.213278\tvalid_0's amex_metric: 0.799769\n",
      "[1800]\tvalid_0's binary_logloss: 0.212985\tvalid_0's amex_metric: 0.799796\n",
      "Early stopping, longdistance iteration is:\n",
      "[175]\t1836\t0.8002665643368886\t0.8003056411938387\n",
      "[1900]\tvalid_0's binary_logloss: 0.21268\tvalid_0's amex_metric: 0.800438\n",
      "[2000]\tvalid_0's binary_logloss: 0.212477\tvalid_0's amex_metric: 0.800504\n",
      "[2100]\tvalid_0's binary_logloss: 0.212296\tvalid_0's amex_metric: 0.8009\n",
      "[2200]\tvalid_0's binary_logloss: 0.212092\tvalid_0's amex_metric: 0.800903\n",
      "[2300]\tvalid_0's binary_logloss: 0.211934\tvalid_0's amex_metric: 0.801357\n",
      "[2400]\tvalid_0's binary_logloss: 0.211762\tvalid_0's amex_metric: 0.80172\n",
      "[2500]\tvalid_0's binary_logloss: 0.211663\tvalid_0's amex_metric: 0.801716\n",
      "[2600]\tvalid_0's binary_logloss: 0.211516\tvalid_0's amex_metric: 0.802134\n",
      "[2700]\tvalid_0's binary_logloss: 0.211408\tvalid_0's amex_metric: 0.802472\n",
      "[2800]\tvalid_0's binary_logloss: 0.211323\tvalid_0's amex_metric: 0.802197\n",
      "[2900]\tvalid_0's binary_logloss: 0.211257\tvalid_0's amex_metric: 0.802318\n",
      "[3000]\tvalid_0's binary_logloss: 0.21113\tvalid_0's amex_metric: 0.802799\n",
      "[3100]\tvalid_0's binary_logloss: 0.211032\tvalid_0's amex_metric: 0.802863\n",
      "[3200]\tvalid_0's binary_logloss: 0.210961\tvalid_0's amex_metric: 0.803019\n",
      "[3300]\tvalid_0's binary_logloss: 0.210872\tvalid_0's amex_metric: 0.803115\n",
      "[3400]\tvalid_0's binary_logloss: 0.210845\tvalid_0's amex_metric: 0.803021\n",
      "Early stopping, longdistance iteration is:\n",
      "[225]\t3457\t0.8035994802200408\t0.8036731130275405\n",
      "[3500]\tvalid_0's binary_logloss: 0.210785\tvalid_0's amex_metric: 0.803646\n",
      "[3600]\tvalid_0's binary_logloss: 0.21074\tvalid_0's amex_metric: 0.803123\n",
      "[3700]\tvalid_0's binary_logloss: 0.210709\tvalid_0's amex_metric: 0.803233\n",
      "[3800]\tvalid_0's binary_logloss: 0.210653\tvalid_0's amex_metric: 0.803017\n",
      "[3900]\tvalid_0's binary_logloss: 0.210599\tvalid_0's amex_metric: 0.802563\n",
      "[4000]\tvalid_0's binary_logloss: 0.210565\tvalid_0's amex_metric: 0.802273\n",
      "[4100]\tvalid_0's binary_logloss: 0.210532\tvalid_0's amex_metric: 0.802182\n",
      "[4200]\tvalid_0's binary_logloss: 0.210506\tvalid_0's amex_metric: 0.802291\n",
      "[4300]\tvalid_0's binary_logloss: 0.210444\tvalid_0's amex_metric: 0.802549\n",
      "[4400]\tvalid_0's binary_logloss: 0.210435\tvalid_0's amex_metric: 0.80279\n",
      "[4500]\tvalid_0's binary_logloss: 0.210401\tvalid_0's amex_metric: 0.80243\n",
      "[4600]\tvalid_0's binary_logloss: 0.210364\tvalid_0's amex_metric: 0.802812\n",
      "[4700]\tvalid_0's binary_logloss: 0.210323\tvalid_0's amex_metric: 0.80303\n",
      "[4800]\tvalid_0's binary_logloss: 0.210283\tvalid_0's amex_metric: 0.80294\n",
      "[4900]\tvalid_0's binary_logloss: 0.210267\tvalid_0's amex_metric: 0.803214\n",
      "[5000]\tvalid_0's binary_logloss: 0.210254\tvalid_0's amex_metric: 0.803084\n",
      "[5100]\tvalid_0's binary_logloss: 0.210236\tvalid_0's amex_metric: 0.802787\n",
      "[5200]\tvalid_0's binary_logloss: 0.21023\tvalid_0's amex_metric: 0.802857\n",
      "[5300]\tvalid_0's binary_logloss: 0.210194\tvalid_0's amex_metric: 0.80287\n",
      "[5400]\tvalid_0's binary_logloss: 0.210209\tvalid_0's amex_metric: 0.802967\n",
      "[5500]\tvalid_0's binary_logloss: 0.210194\tvalid_0's amex_metric: 0.803208\n",
      "[5600]\tvalid_0's binary_logloss: 0.210171\tvalid_0's amex_metric: 0.802714\n",
      "[5700]\tvalid_0's binary_logloss: 0.210154\tvalid_0's amex_metric: 0.803226\n",
      "[5800]\tvalid_0's binary_logloss: 0.21014\tvalid_0's amex_metric: 0.803301\n",
      "[5900]\tvalid_0's binary_logloss: 0.210113\tvalid_0's amex_metric: 0.80358\n",
      "[6000]\tvalid_0's binary_logloss: 0.210107\tvalid_0's amex_metric: 0.803416\n",
      "[6100]\tvalid_0's binary_logloss: 0.210055\tvalid_0's amex_metric: 0.803605\n",
      "[6200]\tvalid_0's binary_logloss: 0.210042\tvalid_0's amex_metric: 0.803172\n",
      "[6300]\tvalid_0's binary_logloss: 0.210024\tvalid_0's amex_metric: 0.803315\n",
      "[6400]\tvalid_0's binary_logloss: 0.210026\tvalid_0's amex_metric: 0.803553\n",
      "[6500]\tvalid_0's binary_logloss: 0.210022\tvalid_0's amex_metric: 0.803458\n",
      "[6600]\tvalid_0's binary_logloss: 0.209992\tvalid_0's amex_metric: 0.803808\n",
      "Early stopping, longdistance iteration is:\n",
      "[3196]\t6667\t0.8039096377358549\t0.8039111100767469\n",
      "[6700]\tvalid_0's binary_logloss: 0.209996\tvalid_0's amex_metric: 0.803843\n",
      "[6800]\tvalid_0's binary_logloss: 0.21\tvalid_0's amex_metric: 0.804013\n",
      "[6900]\tvalid_0's binary_logloss: 0.209993\tvalid_0's amex_metric: 0.804051\n",
      "[7000]\tvalid_0's binary_logloss: 0.209969\tvalid_0's amex_metric: 0.804397\n",
      "[7100]\tvalid_0's binary_logloss: 0.209947\tvalid_0's amex_metric: 0.805112\n",
      "[7200]\tvalid_0's binary_logloss: 0.209928\tvalid_0's amex_metric: 0.805022\n",
      "[7300]\tvalid_0's binary_logloss: 0.20993\tvalid_0's amex_metric: 0.804656\n",
      "[7400]\tvalid_0's binary_logloss: 0.209933\tvalid_0's amex_metric: 0.804659\n",
      "[7500]\tvalid_0's binary_logloss: 0.209958\tvalid_0's amex_metric: 0.805025\n",
      "[7600]\tvalid_0's binary_logloss: 0.20994\tvalid_0's amex_metric: 0.804866\n",
      "[7700]\tvalid_0's binary_logloss: 0.209939\tvalid_0's amex_metric: 0.805036\n",
      "[7800]\tvalid_0's binary_logloss: 0.209964\tvalid_0's amex_metric: 0.804832\n",
      "[7900]\tvalid_0's binary_logloss: 0.209962\tvalid_0's amex_metric: 0.805408\n",
      "[8000]\tvalid_0's binary_logloss: 0.209967\tvalid_0's amex_metric: 0.805681\n",
      "[8100]\tvalid_0's binary_logloss: 0.209985\tvalid_0's amex_metric: 0.805345\n",
      "[8200]\tvalid_0's binary_logloss: 0.209974\tvalid_0's amex_metric: 0.80549\n",
      "[8300]\tvalid_0's binary_logloss: 0.209972\tvalid_0's amex_metric: 0.805527\n",
      "[8400]\tvalid_0's binary_logloss: 0.209975\tvalid_0's amex_metric: 0.804854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8500]\tvalid_0's binary_logloss: 0.209988\tvalid_0's amex_metric: 0.80455\n",
      "[8600]\tvalid_0's binary_logloss: 0.210012\tvalid_0's amex_metric: 0.804784\n",
      "[8700]\tvalid_0's binary_logloss: 0.210015\tvalid_0's amex_metric: 0.805057\n",
      "[8800]\tvalid_0's binary_logloss: 0.210043\tvalid_0's amex_metric: 0.805222\n",
      "[8900]\tvalid_0's binary_logloss: 0.210054\tvalid_0's amex_metric: 0.805327\n",
      "[9000]\tvalid_0's binary_logloss: 0.210055\tvalid_0's amex_metric: 0.805331\n",
      "[9100]\tvalid_0's binary_logloss: 0.21006\tvalid_0's amex_metric: 0.805334\n",
      "[9200]\tvalid_0's binary_logloss: 0.210105\tvalid_0's amex_metric: 0.805055\n",
      "[9300]\tvalid_0's binary_logloss: 0.210105\tvalid_0's amex_metric: 0.804894\n",
      "[9400]\tvalid_0's binary_logloss: 0.210125\tvalid_0's amex_metric: 0.804622\n",
      "[9500]\tvalid_0's binary_logloss: 0.210162\tvalid_0's amex_metric: 0.804718\n",
      "[9600]\tvalid_0's binary_logloss: 0.210181\tvalid_0's amex_metric: 0.804719\n",
      "[9700]\tvalid_0's binary_logloss: 0.210218\tvalid_0's amex_metric: 0.805052\n",
      "[9800]\tvalid_0's binary_logloss: 0.210231\tvalid_0's amex_metric: 0.804584\n",
      "[9900]\tvalid_0's binary_logloss: 0.210254\tvalid_0's amex_metric: 0.804989\n",
      "[10000]\tvalid_0's binary_logloss: 0.210253\tvalid_0's amex_metric: 0.805166\n",
      "[10100]\tvalid_0's binary_logloss: 0.210296\tvalid_0's amex_metric: 0.804924\n",
      "[10200]\tvalid_0's binary_logloss: 0.210299\tvalid_0's amex_metric: 0.804763\n",
      "[10300]\tvalid_0's binary_logloss: 0.210338\tvalid_0's amex_metric: 0.804558\n",
      "[10400]\tvalid_0's binary_logloss: 0.210348\tvalid_0's amex_metric: 0.804729\n",
      "[10500]\tvalid_0's binary_logloss: 0.210344\tvalid_0's amex_metric: 0.804974\n",
      "[10600]\tvalid_0's binary_logloss: 0.210365\tvalid_0's amex_metric: 0.804771\n",
      "[10700]\tvalid_0's binary_logloss: 0.210404\tvalid_0's amex_metric: 0.804498\n",
      "[10800]\tvalid_0's binary_logloss: 0.210411\tvalid_0's amex_metric: 0.804539\n",
      "[10900]\tvalid_0's binary_logloss: 0.210429\tvalid_0's amex_metric: 0.80461\n",
      "[11000]\tvalid_0's binary_logloss: 0.210457\tvalid_0's amex_metric: 0.804374\n",
      "[11100]\tvalid_0's binary_logloss: 0.210497\tvalid_0's amex_metric: 0.804707\n",
      "[11200]\tvalid_0's binary_logloss: 0.210499\tvalid_0's amex_metric: 0.805084\n",
      "[11300]\tvalid_0's binary_logloss: 0.210521\tvalid_0's amex_metric: 0.804883\n",
      "[11400]\tvalid_0's binary_logloss: 0.210547\tvalid_0's amex_metric: 0.805189\n",
      "[11500]\tvalid_0's binary_logloss: 0.210592\tvalid_0's amex_metric: 0.80522\n",
      "[11600]\tvalid_0's binary_logloss: 0.210634\tvalid_0's amex_metric: 0.805517\n",
      "[11700]\tvalid_0's binary_logloss: 0.210668\tvalid_0's amex_metric: 0.805211\n",
      "[11800]\tvalid_0's binary_logloss: 0.210684\tvalid_0's amex_metric: 0.804711\n",
      "[11900]\tvalid_0's binary_logloss: 0.210712\tvalid_0's amex_metric: 0.805181\n",
      "[12000]\tvalid_0's binary_logloss: 0.210753\tvalid_0's amex_metric: 0.80501\n",
      "[12100]\tvalid_0's binary_logloss: 0.210777\tvalid_0's amex_metric: 0.80491\n",
      "[12200]\tvalid_0's binary_logloss: 0.210817\tvalid_0's amex_metric: 0.805077\n",
      "[12300]\tvalid_0's binary_logloss: 0.21085\tvalid_0's amex_metric: 0.805076\n",
      "[12400]\tvalid_0's binary_logloss: 0.210874\tvalid_0's amex_metric: 0.805079\n",
      "[12500]\tvalid_0's binary_logloss: 0.210909\tvalid_0's amex_metric: 0.805079\n",
      "[12600]\tvalid_0's binary_logloss: 0.21094\tvalid_0's amex_metric: 0.804943\n",
      "[12700]\tvalid_0's binary_logloss: 0.210982\tvalid_0's amex_metric: 0.804871\n",
      "[12800]\tvalid_0's binary_logloss: 0.211029\tvalid_0's amex_metric: 0.804898\n",
      "[12900]\tvalid_0's binary_logloss: 0.211058\tvalid_0's amex_metric: 0.805069\n",
      "[13000]\tvalid_0's binary_logloss: 0.211074\tvalid_0's amex_metric: 0.805008\n",
      "[13100]\tvalid_0's binary_logloss: 0.211122\tvalid_0's amex_metric: 0.805039\n",
      "[13200]\tvalid_0's binary_logloss: 0.211169\tvalid_0's amex_metric: 0.805004\n",
      "Early stopping, best iteration is:\n",
      "[7259]\tvalid_0's binary_logloss: 0.209913\tvalid_0's amex_metric: 0.80466\n",
      "ready to Predict validation\n",
      "ready to Add to out of folds array\n",
      "ready to Predict the test set\n",
      "Our fold 0 CV score is 0.8046596203220087\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 1 with 1365 features...\n",
      "[LightGBM] [Info] Number of positive: 103975, number of negative: 297574\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.340716 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 224041\n",
      "[LightGBM] [Info] Number of data points in the train set: 401549, number of used features: 1357\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258935 -> initscore=-1.051512\n",
      "[LightGBM] [Info] Start training from score -1.051512\n",
      "Training until validation scores don't improve for 6000 rounds\n",
      "Early stopping, longdistance iteration is:\n",
      "[1]\t1\t0.7059037004593558\t0.721736754368038\n",
      "Early stopping, longdistance iteration is:\n",
      "[2]\t4\t0.727702176849121\t0.7358134324204905\n",
      "Early stopping, longdistance iteration is:\n",
      "[4]\t24\t0.7502786222024054\t0.7504264975111701\n",
      "Early stopping, longdistance iteration is:\n",
      "[5]\t43\t0.7532410375547356\t0.7534606457647741\n",
      "Early stopping, longdistance iteration is:\n",
      "[6]\t50\t0.7536684328731984\t0.7540491541254237\n",
      "Early stopping, longdistance iteration is:\n",
      "[13]\t70\t0.7554223398920581\t0.7559949927459199\n",
      "Early stopping, longdistance iteration is:\n",
      "[15]\t90\t0.7565802165630797\t0.7566562961971115\n",
      "[100]\tvalid_0's binary_logloss: 0.379513\tvalid_0's amex_metric: 0.756636\n",
      "Early stopping, longdistance iteration is:\n",
      "[18]\t185\t0.7608178463469226\t0.7613073447823047\n",
      "[200]\tvalid_0's binary_logloss: 0.303807\tvalid_0's amex_metric: 0.761563\n",
      "[300]\tvalid_0's binary_logloss: 0.267857\tvalid_0's amex_metric: 0.767595\n",
      "[400]\tvalid_0's binary_logloss: 0.24928\tvalid_0's amex_metric: 0.772357\n",
      "Early stopping, longdistance iteration is:\n",
      "[23]\t437\t0.7728606086494729\t0.7729299605037567\n",
      "[500]\tvalid_0's binary_logloss: 0.239109\tvalid_0's amex_metric: 0.774716\n",
      "[600]\tvalid_0's binary_logloss: 0.233174\tvalid_0's amex_metric: 0.777252\n",
      "[700]\tvalid_0's binary_logloss: 0.229521\tvalid_0's amex_metric: 0.779755\n",
      "[800]\tvalid_0's binary_logloss: 0.227144\tvalid_0's amex_metric: 0.781664\n",
      "Early stopping, longdistance iteration is:\n",
      "[25]\t817\t0.7821044986368695\t0.7823275975439655\n",
      "[900]\tvalid_0's binary_logloss: 0.225557\tvalid_0's amex_metric: 0.782608\n",
      "Early stopping, longdistance iteration is:\n",
      "[31]\t957\t0.7831120919754164\t0.7831276223353163\n",
      "Early stopping, longdistance iteration is:\n",
      "[33]\t990\t0.7831276223353163\t0.783138589833629\n",
      "[1000]\tvalid_0's binary_logloss: 0.224336\tvalid_0's amex_metric: 0.783302\n",
      "Early stopping, longdistance iteration is:\n",
      "[44]\t1091\t0.7842279732675547\t0.7843526862050165\n",
      "[1100]\tvalid_0's binary_logloss: 0.223408\tvalid_0's amex_metric: 0.784037\n",
      "Early stopping, longdistance iteration is:\n",
      "[62]\t1169\t0.7846985455675781\t0.7847570564681775\n",
      "[1200]\tvalid_0's binary_logloss: 0.222639\tvalid_0's amex_metric: 0.784693\n",
      "[1300]\tvalid_0's binary_logloss: 0.222023\tvalid_0's amex_metric: 0.786278\n",
      "[1400]\tvalid_0's binary_logloss: 0.221556\tvalid_0's amex_metric: 0.786742\n",
      "Early stopping, longdistance iteration is:\n",
      "[72]\t1437\t0.7870306552575241\t0.7871412488228755\n",
      "[1500]\tvalid_0's binary_logloss: 0.221095\tvalid_0's amex_metric: 0.786846\n",
      "[1600]\tvalid_0's binary_logloss: 0.220719\tvalid_0's amex_metric: 0.786808\n",
      "Early stopping, longdistance iteration is:\n",
      "[158]\t1627\t0.7872675804854713\t0.7873781533041881\n",
      "[1700]\tvalid_0's binary_logloss: 0.220363\tvalid_0's amex_metric: 0.787406\n",
      "[1800]\tvalid_0's binary_logloss: 0.220097\tvalid_0's amex_metric: 0.788781\n",
      "[1900]\tvalid_0's binary_logloss: 0.219857\tvalid_0's amex_metric: 0.788564\n",
      "[2000]\tvalid_0's binary_logloss: 0.219684\tvalid_0's amex_metric: 0.788623\n",
      "[2100]\tvalid_0's binary_logloss: 0.219507\tvalid_0's amex_metric: 0.789091\n",
      "[2200]\tvalid_0's binary_logloss: 0.219348\tvalid_0's amex_metric: 0.788877\n",
      "[2300]\tvalid_0's binary_logloss: 0.219216\tvalid_0's amex_metric: 0.789093\n",
      "Early stopping, longdistance iteration is:\n",
      "[279]\t2395\t0.7894402462241626\t0.789446026800232\n",
      "[2400]\tvalid_0's binary_logloss: 0.219069\tvalid_0's amex_metric: 0.789279\n",
      "[2500]\tvalid_0's binary_logloss: 0.218928\tvalid_0's amex_metric: 0.789432\n",
      "[2600]\tvalid_0's binary_logloss: 0.218808\tvalid_0's amex_metric: 0.790082\n",
      "[2700]\tvalid_0's binary_logloss: 0.218733\tvalid_0's amex_metric: 0.789575\n",
      "[2800]\tvalid_0's binary_logloss: 0.218628\tvalid_0's amex_metric: 0.78934\n",
      "[2900]\tvalid_0's binary_logloss: 0.21854\tvalid_0's amex_metric: 0.789239\n",
      "[3000]\tvalid_0's binary_logloss: 0.218485\tvalid_0's amex_metric: 0.788923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3100]\tvalid_0's binary_logloss: 0.218433\tvalid_0's amex_metric: 0.789345\n",
      "[3200]\tvalid_0's binary_logloss: 0.218381\tvalid_0's amex_metric: 0.789333\n",
      "[3300]\tvalid_0's binary_logloss: 0.218302\tvalid_0's amex_metric: 0.789666\n",
      "Early stopping, longdistance iteration is:\n",
      "[728]\t3350\t0.7902597123510018\t0.7903185827164732\n",
      "[3400]\tvalid_0's binary_logloss: 0.218221\tvalid_0's amex_metric: 0.789899\n",
      "[3500]\tvalid_0's binary_logloss: 0.218166\tvalid_0's amex_metric: 0.789957\n",
      "[3600]\tvalid_0's binary_logloss: 0.218109\tvalid_0's amex_metric: 0.789979\n",
      "[3700]\tvalid_0's binary_logloss: 0.21808\tvalid_0's amex_metric: 0.789958\n",
      "[3800]\tvalid_0's binary_logloss: 0.218038\tvalid_0's amex_metric: 0.789975\n",
      "[3900]\tvalid_0's binary_logloss: 0.218003\tvalid_0's amex_metric: 0.790227\n",
      "[4000]\tvalid_0's binary_logloss: 0.217945\tvalid_0's amex_metric: 0.789609\n",
      "[4100]\tvalid_0's binary_logloss: 0.217882\tvalid_0's amex_metric: 0.789635\n",
      "[4200]\tvalid_0's binary_logloss: 0.217851\tvalid_0's amex_metric: 0.789988\n",
      "[4300]\tvalid_0's binary_logloss: 0.217815\tvalid_0's amex_metric: 0.789703\n",
      "[4400]\tvalid_0's binary_logloss: 0.217786\tvalid_0's amex_metric: 0.789416\n",
      "[4500]\tvalid_0's binary_logloss: 0.217736\tvalid_0's amex_metric: 0.790074\n",
      "[4600]\tvalid_0's binary_logloss: 0.217723\tvalid_0's amex_metric: 0.790084\n",
      "Early stopping, longdistance iteration is:\n",
      "[773]\t4637\t0.7905209721552888\t0.7905265674294473\n",
      "[4700]\tvalid_0's binary_logloss: 0.217687\tvalid_0's amex_metric: 0.790165\n",
      "[4800]\tvalid_0's binary_logloss: 0.217655\tvalid_0's amex_metric: 0.790143\n",
      "[4900]\tvalid_0's binary_logloss: 0.217672\tvalid_0's amex_metric: 0.789771\n",
      "[5000]\tvalid_0's binary_logloss: 0.217657\tvalid_0's amex_metric: 0.790013\n",
      "[5100]\tvalid_0's binary_logloss: 0.217645\tvalid_0's amex_metric: 0.790156\n",
      "[5200]\tvalid_0's binary_logloss: 0.217644\tvalid_0's amex_metric: 0.790191\n",
      "[5300]\tvalid_0's binary_logloss: 0.217634\tvalid_0's amex_metric: 0.790333\n",
      "[5400]\tvalid_0's binary_logloss: 0.217617\tvalid_0's amex_metric: 0.790173\n",
      "[5500]\tvalid_0's binary_logloss: 0.217589\tvalid_0's amex_metric: 0.790321\n",
      "[5600]\tvalid_0's binary_logloss: 0.217566\tvalid_0's amex_metric: 0.790504\n",
      "Early stopping, longdistance iteration is:\n",
      "[972]\t5611\t0.7907286830323721\t0.790740198570044\n",
      "[5700]\tvalid_0's binary_logloss: 0.217544\tvalid_0's amex_metric: 0.790213\n",
      "[5800]\tvalid_0's binary_logloss: 0.217533\tvalid_0's amex_metric: 0.790324\n",
      "[5900]\tvalid_0's binary_logloss: 0.21755\tvalid_0's amex_metric: 0.790592\n",
      "[6000]\tvalid_0's binary_logloss: 0.217523\tvalid_0's amex_metric: 0.790233\n",
      "[6100]\tvalid_0's binary_logloss: 0.217534\tvalid_0's amex_metric: 0.790371\n",
      "[6200]\tvalid_0's binary_logloss: 0.21752\tvalid_0's amex_metric: 0.790716\n",
      "[6300]\tvalid_0's binary_logloss: 0.217545\tvalid_0's amex_metric: 0.790711\n",
      "[6400]\tvalid_0's binary_logloss: 0.21756\tvalid_0's amex_metric: 0.790743\n",
      "[6500]\tvalid_0's binary_logloss: 0.217585\tvalid_0's amex_metric: 0.790742\n",
      "[6600]\tvalid_0's binary_logloss: 0.217592\tvalid_0's amex_metric: 0.790712\n",
      "[6700]\tvalid_0's binary_logloss: 0.217602\tvalid_0's amex_metric: 0.790579\n",
      "[6800]\tvalid_0's binary_logloss: 0.217595\tvalid_0's amex_metric: 0.79042\n",
      "[6900]\tvalid_0's binary_logloss: 0.217591\tvalid_0's amex_metric: 0.790459\n",
      "[7000]\tvalid_0's binary_logloss: 0.217604\tvalid_0's amex_metric: 0.790664\n",
      "[7100]\tvalid_0's binary_logloss: 0.217606\tvalid_0's amex_metric: 0.790332\n",
      "[7200]\tvalid_0's binary_logloss: 0.217621\tvalid_0's amex_metric: 0.790905\n",
      "[7300]\tvalid_0's binary_logloss: 0.217625\tvalid_0's amex_metric: 0.790806\n",
      "[7400]\tvalid_0's binary_logloss: 0.217675\tvalid_0's amex_metric: 0.790596\n",
      "[7500]\tvalid_0's binary_logloss: 0.217641\tvalid_0's amex_metric: 0.790544\n",
      "[7600]\tvalid_0's binary_logloss: 0.217654\tvalid_0's amex_metric: 0.790277\n",
      "[7700]\tvalid_0's binary_logloss: 0.217657\tvalid_0's amex_metric: 0.790317\n",
      "[7800]\tvalid_0's binary_logloss: 0.217669\tvalid_0's amex_metric: 0.790319\n",
      "[7900]\tvalid_0's binary_logloss: 0.21769\tvalid_0's amex_metric: 0.790455\n",
      "[8000]\tvalid_0's binary_logloss: 0.217707\tvalid_0's amex_metric: 0.790691\n",
      "[8100]\tvalid_0's binary_logloss: 0.217724\tvalid_0's amex_metric: 0.790862\n",
      "Early stopping, longdistance iteration is:\n",
      "[1211]\t8179\t0.7911361734412796\t0.791140109074657\n",
      "[8200]\tvalid_0's binary_logloss: 0.217719\tvalid_0's amex_metric: 0.790973\n",
      "[8300]\tvalid_0's binary_logloss: 0.217736\tvalid_0's amex_metric: 0.791009\n",
      "[8400]\tvalid_0's binary_logloss: 0.217794\tvalid_0's amex_metric: 0.790968\n",
      "[8500]\tvalid_0's binary_logloss: 0.21779\tvalid_0's amex_metric: 0.79128\n",
      "[8600]\tvalid_0's binary_logloss: 0.217816\tvalid_0's amex_metric: 0.791212\n",
      "[8700]\tvalid_0's binary_logloss: 0.217841\tvalid_0's amex_metric: 0.791413\n",
      "[8800]\tvalid_0's binary_logloss: 0.217848\tvalid_0's amex_metric: 0.790984\n",
      "[8900]\tvalid_0's binary_logloss: 0.217843\tvalid_0's amex_metric: 0.790623\n",
      "[9000]\tvalid_0's binary_logloss: 0.217882\tvalid_0's amex_metric: 0.790755\n",
      "[9100]\tvalid_0's binary_logloss: 0.217909\tvalid_0's amex_metric: 0.790891\n",
      "[9200]\tvalid_0's binary_logloss: 0.217957\tvalid_0's amex_metric: 0.790956\n",
      "[9300]\tvalid_0's binary_logloss: 0.217978\tvalid_0's amex_metric: 0.790992\n",
      "[9400]\tvalid_0's binary_logloss: 0.217996\tvalid_0's amex_metric: 0.79086\n",
      "[9500]\tvalid_0's binary_logloss: 0.218008\tvalid_0's amex_metric: 0.790696\n",
      "[9600]\tvalid_0's binary_logloss: 0.218054\tvalid_0's amex_metric: 0.790925\n",
      "[9700]\tvalid_0's binary_logloss: 0.218066\tvalid_0's amex_metric: 0.79053\n",
      "[9800]\tvalid_0's binary_logloss: 0.218087\tvalid_0's amex_metric: 0.790532\n",
      "[9900]\tvalid_0's binary_logloss: 0.218113\tvalid_0's amex_metric: 0.790436\n",
      "[10000]\tvalid_0's binary_logloss: 0.218141\tvalid_0's amex_metric: 0.790707\n",
      "[10100]\tvalid_0's binary_logloss: 0.218153\tvalid_0's amex_metric: 0.790343\n",
      "[10200]\tvalid_0's binary_logloss: 0.218167\tvalid_0's amex_metric: 0.79011\n",
      "[10300]\tvalid_0's binary_logloss: 0.218208\tvalid_0's amex_metric: 0.790782\n",
      "[10400]\tvalid_0's binary_logloss: 0.218238\tvalid_0's amex_metric: 0.790348\n",
      "[10500]\tvalid_0's binary_logloss: 0.218286\tvalid_0's amex_metric: 0.790444\n",
      "[10600]\tvalid_0's binary_logloss: 0.218327\tvalid_0's amex_metric: 0.789903\n",
      "[10700]\tvalid_0's binary_logloss: 0.218344\tvalid_0's amex_metric: 0.790413\n",
      "[10800]\tvalid_0's binary_logloss: 0.218362\tvalid_0's amex_metric: 0.790084\n",
      "[10900]\tvalid_0's binary_logloss: 0.21839\tvalid_0's amex_metric: 0.790527\n",
      "[11000]\tvalid_0's binary_logloss: 0.218409\tvalid_0's amex_metric: 0.790393\n",
      "[11100]\tvalid_0's binary_logloss: 0.218432\tvalid_0's amex_metric: 0.790566\n",
      "[11200]\tvalid_0's binary_logloss: 0.218474\tvalid_0's amex_metric: 0.790364\n",
      "[11300]\tvalid_0's binary_logloss: 0.218511\tvalid_0's amex_metric: 0.790603\n",
      "[11400]\tvalid_0's binary_logloss: 0.218544\tvalid_0's amex_metric: 0.790235\n",
      "[11500]\tvalid_0's binary_logloss: 0.218583\tvalid_0's amex_metric: 0.790134\n",
      "[11600]\tvalid_0's binary_logloss: 0.218634\tvalid_0's amex_metric: 0.790467\n",
      "[11700]\tvalid_0's binary_logloss: 0.218671\tvalid_0's amex_metric: 0.790538\n",
      "[11800]\tvalid_0's binary_logloss: 0.218699\tvalid_0's amex_metric: 0.790377\n",
      "[11900]\tvalid_0's binary_logloss: 0.218758\tvalid_0's amex_metric: 0.790203\n",
      "[12000]\tvalid_0's binary_logloss: 0.218781\tvalid_0's amex_metric: 0.790105\n",
      "Early stopping, best iteration is:\n",
      "[6044]\tvalid_0's binary_logloss: 0.217504\tvalid_0's amex_metric: 0.790409\n",
      "ready to Predict validation\n",
      "ready to Add to out of folds array\n",
      "ready to Predict the test set\n",
      "Our fold 1 CV score is 0.7904094182434436\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 2 with 1365 features...\n",
      "[LightGBM] [Info] Number of positive: 103975, number of negative: 297574\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.681852 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 224388\n",
      "[LightGBM] [Info] Number of data points in the train set: 401549, number of used features: 1357\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258935 -> initscore=-1.051512\n",
      "[LightGBM] [Info] Start training from score -1.051512\n",
      "Training until validation scores don't improve for 6000 rounds\n",
      "Early stopping, longdistance iteration is:\n",
      "[1]\t1\t0.7163208082205419\t0.7311661805688972\n",
      "Early stopping, longdistance iteration is:\n",
      "[3]\t10\t0.7520853647136566\t0.7535013849459278\n",
      "Early stopping, longdistance iteration is:\n",
      "[5]\t16\t0.7574546953946648\t0.758483733021517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, longdistance iteration is:\n",
      "[16]\t54\t0.7637089395213377\t0.7637102995131961\n",
      "[100]\tvalid_0's binary_logloss: 0.377959\tvalid_0's amex_metric: 0.767312\n",
      "[200]\tvalid_0's binary_logloss: 0.30129\tvalid_0's amex_metric: 0.77198\n",
      "[300]\tvalid_0's binary_logloss: 0.26447\tvalid_0's amex_metric: 0.776247\n",
      "Early stopping, longdistance iteration is:\n",
      "[18]\t323\t0.7769239949344557\t0.7770652171110364\n",
      "[400]\tvalid_0's binary_logloss: 0.245076\tvalid_0's amex_metric: 0.779119\n",
      "[500]\tvalid_0's binary_logloss: 0.234234\tvalid_0's amex_metric: 0.782306\n",
      "[600]\tvalid_0's binary_logloss: 0.227883\tvalid_0's amex_metric: 0.785971\n",
      "Early stopping, longdistance iteration is:\n",
      "[23]\t693\t0.7879877116976883\t0.7880203278440524\n",
      "[700]\tvalid_0's binary_logloss: 0.223841\tvalid_0's amex_metric: 0.788493\n",
      "[800]\tvalid_0's binary_logloss: 0.221141\tvalid_0's amex_metric: 0.790639\n",
      "[900]\tvalid_0's binary_logloss: 0.219269\tvalid_0's amex_metric: 0.792562\n",
      "Early stopping, longdistance iteration is:\n",
      "[27]\t930\t0.7929454466097152\t0.7929754258198562\n",
      "Early stopping, longdistance iteration is:\n",
      "[37]\t981\t0.7932902937812294\t0.7933070214765545\n",
      "[1000]\tvalid_0's binary_logloss: 0.217927\tvalid_0's amex_metric: 0.793091\n",
      "[1100]\tvalid_0's binary_logloss: 0.216898\tvalid_0's amex_metric: 0.794412\n",
      "Early stopping, longdistance iteration is:\n",
      "[40]\t1199\t0.7955229848264149\t0.7955687923565795\n",
      "[1200]\tvalid_0's binary_logloss: 0.216126\tvalid_0's amex_metric: 0.795569\n",
      "[1300]\tvalid_0's binary_logloss: 0.215472\tvalid_0's amex_metric: 0.796564\n",
      "[1400]\tvalid_0's binary_logloss: 0.214908\tvalid_0's amex_metric: 0.798182\n",
      "Early stopping, longdistance iteration is:\n",
      "[41]\t1472\t0.7985961086162187\t0.7986199919211308\n",
      "[1500]\tvalid_0's binary_logloss: 0.214444\tvalid_0's amex_metric: 0.798492\n",
      "[1600]\tvalid_0's binary_logloss: 0.214077\tvalid_0's amex_metric: 0.798804\n",
      "Early stopping, longdistance iteration is:\n",
      "[95]\t1604\t0.7990387748177058\t0.7990442957068554\n",
      "[1700]\tvalid_0's binary_logloss: 0.213719\tvalid_0's amex_metric: 0.799854\n",
      "[1800]\tvalid_0's binary_logloss: 0.21345\tvalid_0's amex_metric: 0.799871\n",
      "[1900]\tvalid_0's binary_logloss: 0.213169\tvalid_0's amex_metric: 0.800095\n",
      "Early stopping, longdistance iteration is:\n",
      "[141]\t1933\t0.8001371428611178\t0.8001486931893731\n",
      "[2000]\tvalid_0's binary_logloss: 0.21297\tvalid_0's amex_metric: 0.800121\n",
      "[2100]\tvalid_0's binary_logloss: 0.21279\tvalid_0's amex_metric: 0.800545\n",
      "[2200]\tvalid_0's binary_logloss: 0.212625\tvalid_0's amex_metric: 0.800731\n",
      "[2300]\tvalid_0's binary_logloss: 0.212465\tvalid_0's amex_metric: 0.801081\n",
      "[2400]\tvalid_0's binary_logloss: 0.212311\tvalid_0's amex_metric: 0.800928\n",
      "[2500]\tvalid_0's binary_logloss: 0.212186\tvalid_0's amex_metric: 0.801339\n",
      "Early stopping, longdistance iteration is:\n",
      "[154]\t2531\t0.8017990876574155\t0.801824838235431\n",
      "[2600]\tvalid_0's binary_logloss: 0.212064\tvalid_0's amex_metric: 0.801848\n",
      "[2700]\tvalid_0's binary_logloss: 0.211948\tvalid_0's amex_metric: 0.802492\n",
      "[2800]\tvalid_0's binary_logloss: 0.211877\tvalid_0's amex_metric: 0.80278\n",
      "[2900]\tvalid_0's binary_logloss: 0.211786\tvalid_0's amex_metric: 0.802505\n",
      "Early stopping, longdistance iteration is:\n",
      "[164]\t2977\t0.8030881176384066\t0.8031062074869889\n",
      "[3000]\tvalid_0's binary_logloss: 0.211689\tvalid_0's amex_metric: 0.802571\n",
      "[3100]\tvalid_0's binary_logloss: 0.211625\tvalid_0's amex_metric: 0.802862\n",
      "[3200]\tvalid_0's binary_logloss: 0.211555\tvalid_0's amex_metric: 0.802549\n",
      "[3300]\tvalid_0's binary_logloss: 0.211513\tvalid_0's amex_metric: 0.802829\n",
      "Early stopping, longdistance iteration is:\n",
      "[275]\t3335\t0.8032187429204967\t0.803240100101066\n",
      "[3400]\tvalid_0's binary_logloss: 0.211424\tvalid_0's amex_metric: 0.803158\n",
      "[3500]\tvalid_0's binary_logloss: 0.211353\tvalid_0's amex_metric: 0.803348\n",
      "[3600]\tvalid_0's binary_logloss: 0.211295\tvalid_0's amex_metric: 0.803365\n",
      "[3700]\tvalid_0's binary_logloss: 0.211244\tvalid_0's amex_metric: 0.803379\n",
      "[3800]\tvalid_0's binary_logloss: 0.211183\tvalid_0's amex_metric: 0.804005\n",
      "[3900]\tvalid_0's binary_logloss: 0.211143\tvalid_0's amex_metric: 0.804084\n",
      "[4000]\tvalid_0's binary_logloss: 0.211136\tvalid_0's amex_metric: 0.803848\n",
      "[4100]\tvalid_0's binary_logloss: 0.211083\tvalid_0's amex_metric: 0.803931\n",
      "[4200]\tvalid_0's binary_logloss: 0.211051\tvalid_0's amex_metric: 0.803706\n",
      "[4300]\tvalid_0's binary_logloss: 0.211006\tvalid_0's amex_metric: 0.803687\n",
      "[4400]\tvalid_0's binary_logloss: 0.21098\tvalid_0's amex_metric: 0.803561\n",
      "[4500]\tvalid_0's binary_logloss: 0.210949\tvalid_0's amex_metric: 0.803471\n",
      "[4600]\tvalid_0's binary_logloss: 0.210905\tvalid_0's amex_metric: 0.802912\n",
      "[4700]\tvalid_0's binary_logloss: 0.210897\tvalid_0's amex_metric: 0.803654\n",
      "[4800]\tvalid_0's binary_logloss: 0.210856\tvalid_0's amex_metric: 0.8035\n",
      "[4900]\tvalid_0's binary_logloss: 0.210861\tvalid_0's amex_metric: 0.803498\n",
      "[5000]\tvalid_0's binary_logloss: 0.210851\tvalid_0's amex_metric: 0.803535\n",
      "[5100]\tvalid_0's binary_logloss: 0.210825\tvalid_0's amex_metric: 0.803341\n",
      "[5200]\tvalid_0's binary_logloss: 0.210811\tvalid_0's amex_metric: 0.80351\n",
      "[5300]\tvalid_0's binary_logloss: 0.210805\tvalid_0's amex_metric: 0.803812\n",
      "[5400]\tvalid_0's binary_logloss: 0.210791\tvalid_0's amex_metric: 0.80402\n",
      "Early stopping, longdistance iteration is:\n",
      "[1544]\t5462\t0.8043229964893499\t0.8044246242930057\n",
      "[5500]\tvalid_0's binary_logloss: 0.210791\tvalid_0's amex_metric: 0.803819\n",
      "[5600]\tvalid_0's binary_logloss: 0.210744\tvalid_0's amex_metric: 0.80444\n",
      "[5700]\tvalid_0's binary_logloss: 0.210754\tvalid_0's amex_metric: 0.804236\n",
      "[5800]\tvalid_0's binary_logloss: 0.210745\tvalid_0's amex_metric: 0.804207\n",
      "[5900]\tvalid_0's binary_logloss: 0.210715\tvalid_0's amex_metric: 0.803982\n",
      "[6000]\tvalid_0's binary_logloss: 0.210686\tvalid_0's amex_metric: 0.804229\n",
      "[6100]\tvalid_0's binary_logloss: 0.210654\tvalid_0's amex_metric: 0.80377\n",
      "[6200]\tvalid_0's binary_logloss: 0.210645\tvalid_0's amex_metric: 0.803438\n",
      "[6300]\tvalid_0's binary_logloss: 0.210626\tvalid_0's amex_metric: 0.803379\n",
      "[6400]\tvalid_0's binary_logloss: 0.210637\tvalid_0's amex_metric: 0.803947\n",
      "[6500]\tvalid_0's binary_logloss: 0.210636\tvalid_0's amex_metric: 0.803543\n",
      "[6600]\tvalid_0's binary_logloss: 0.210644\tvalid_0's amex_metric: 0.803911\n",
      "[6700]\tvalid_0's binary_logloss: 0.210636\tvalid_0's amex_metric: 0.804188\n",
      "[6800]\tvalid_0's binary_logloss: 0.210637\tvalid_0's amex_metric: 0.804254\n",
      "[6900]\tvalid_0's binary_logloss: 0.210621\tvalid_0's amex_metric: 0.804193\n",
      "[7000]\tvalid_0's binary_logloss: 0.210633\tvalid_0's amex_metric: 0.804528\n",
      "[7100]\tvalid_0's binary_logloss: 0.210633\tvalid_0's amex_metric: 0.804261\n",
      "[7200]\tvalid_0's binary_logloss: 0.210663\tvalid_0's amex_metric: 0.804558\n",
      "[7300]\tvalid_0's binary_logloss: 0.210672\tvalid_0's amex_metric: 0.804488\n",
      "[7400]\tvalid_0's binary_logloss: 0.210665\tvalid_0's amex_metric: 0.804425\n",
      "Early stopping, longdistance iteration is:\n",
      "[1715]\t7470\t0.8049490279051413\t0.8049668310900833\n",
      "[7500]\tvalid_0's binary_logloss: 0.210664\tvalid_0's amex_metric: 0.805304\n",
      "[7600]\tvalid_0's binary_logloss: 0.210666\tvalid_0's amex_metric: 0.804935\n",
      "[7700]\tvalid_0's binary_logloss: 0.210685\tvalid_0's amex_metric: 0.80473\n",
      "[7800]\tvalid_0's binary_logloss: 0.210729\tvalid_0's amex_metric: 0.804888\n",
      "[7900]\tvalid_0's binary_logloss: 0.210735\tvalid_0's amex_metric: 0.804789\n",
      "[8000]\tvalid_0's binary_logloss: 0.210728\tvalid_0's amex_metric: 0.804627\n",
      "[8100]\tvalid_0's binary_logloss: 0.210738\tvalid_0's amex_metric: 0.804256\n",
      "[8200]\tvalid_0's binary_logloss: 0.210722\tvalid_0's amex_metric: 0.804936\n",
      "[8300]\tvalid_0's binary_logloss: 0.210722\tvalid_0's amex_metric: 0.804739\n",
      "[8400]\tvalid_0's binary_logloss: 0.210708\tvalid_0's amex_metric: 0.805286\n",
      "[8500]\tvalid_0's binary_logloss: 0.210718\tvalid_0's amex_metric: 0.805255\n",
      "[8600]\tvalid_0's binary_logloss: 0.21071\tvalid_0's amex_metric: 0.805026\n",
      "[8700]\tvalid_0's binary_logloss: 0.210725\tvalid_0's amex_metric: 0.804956\n",
      "[8800]\tvalid_0's binary_logloss: 0.210735\tvalid_0's amex_metric: 0.805258\n",
      "[8900]\tvalid_0's binary_logloss: 0.210755\tvalid_0's amex_metric: 0.805221\n",
      "[9000]\tvalid_0's binary_logloss: 0.210759\tvalid_0's amex_metric: 0.804622\n",
      "[9100]\tvalid_0's binary_logloss: 0.210796\tvalid_0's amex_metric: 0.804478\n",
      "[9200]\tvalid_0's binary_logloss: 0.210819\tvalid_0's amex_metric: 0.804879\n",
      "[9300]\tvalid_0's binary_logloss: 0.21081\tvalid_0's amex_metric: 0.805192\n",
      "[9400]\tvalid_0's binary_logloss: 0.210817\tvalid_0's amex_metric: 0.80506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9500]\tvalid_0's binary_logloss: 0.210838\tvalid_0's amex_metric: 0.804959\n",
      "[9600]\tvalid_0's binary_logloss: 0.210838\tvalid_0's amex_metric: 0.804963\n",
      "[9700]\tvalid_0's binary_logloss: 0.210842\tvalid_0's amex_metric: 0.804966\n",
      "[9800]\tvalid_0's binary_logloss: 0.21086\tvalid_0's amex_metric: 0.805302\n",
      "[9900]\tvalid_0's binary_logloss: 0.210906\tvalid_0's amex_metric: 0.804922\n",
      "[10000]\tvalid_0's binary_logloss: 0.210921\tvalid_0's amex_metric: 0.804957\n",
      "[10100]\tvalid_0's binary_logloss: 0.210959\tvalid_0's amex_metric: 0.804783\n",
      "[10200]\tvalid_0's binary_logloss: 0.211001\tvalid_0's amex_metric: 0.804947\n",
      "[10300]\tvalid_0's binary_logloss: 0.211017\tvalid_0's amex_metric: 0.804407\n",
      "[10400]\tvalid_0's binary_logloss: 0.211029\tvalid_0's amex_metric: 0.804813\n",
      "[10500]\tvalid_0's binary_logloss: 0.211053\tvalid_0's amex_metric: 0.804946\n",
      "[10600]\tvalid_0's binary_logloss: 0.211057\tvalid_0's amex_metric: 0.804953\n",
      "[10700]\tvalid_0's binary_logloss: 0.211081\tvalid_0's amex_metric: 0.804952\n",
      "[10800]\tvalid_0's binary_logloss: 0.211091\tvalid_0's amex_metric: 0.805055\n",
      "[10900]\tvalid_0's binary_logloss: 0.211115\tvalid_0's amex_metric: 0.805154\n",
      "Early stopping, longdistance iteration is:\n",
      "[2113]\t10974\t0.8055586466922118\t0.8056010872174593\n",
      "[11000]\tvalid_0's binary_logloss: 0.21111\tvalid_0's amex_metric: 0.805468\n",
      "[11100]\tvalid_0's binary_logloss: 0.211129\tvalid_0's amex_metric: 0.805432\n",
      "[11200]\tvalid_0's binary_logloss: 0.211186\tvalid_0's amex_metric: 0.805457\n",
      "[11300]\tvalid_0's binary_logloss: 0.211211\tvalid_0's amex_metric: 0.80512\n",
      "[11400]\tvalid_0's binary_logloss: 0.211235\tvalid_0's amex_metric: 0.804952\n",
      "[11500]\tvalid_0's binary_logloss: 0.211277\tvalid_0's amex_metric: 0.805016\n",
      "[11600]\tvalid_0's binary_logloss: 0.211315\tvalid_0's amex_metric: 0.804913\n",
      "[11700]\tvalid_0's binary_logloss: 0.211338\tvalid_0's amex_metric: 0.804948\n",
      "[11800]\tvalid_0's binary_logloss: 0.211384\tvalid_0's amex_metric: 0.805079\n",
      "[11900]\tvalid_0's binary_logloss: 0.211417\tvalid_0's amex_metric: 0.804841\n",
      "[12000]\tvalid_0's binary_logloss: 0.211451\tvalid_0's amex_metric: 0.804634\n",
      "[12100]\tvalid_0's binary_logloss: 0.211488\tvalid_0's amex_metric: 0.804898\n",
      "[12200]\tvalid_0's binary_logloss: 0.211506\tvalid_0's amex_metric: 0.804934\n",
      "[12300]\tvalid_0's binary_logloss: 0.211532\tvalid_0's amex_metric: 0.804837\n",
      "[12400]\tvalid_0's binary_logloss: 0.211557\tvalid_0's amex_metric: 0.804938\n",
      "[12500]\tvalid_0's binary_logloss: 0.211616\tvalid_0's amex_metric: 0.804895\n",
      "[12600]\tvalid_0's binary_logloss: 0.211655\tvalid_0's amex_metric: 0.804254\n",
      "[12700]\tvalid_0's binary_logloss: 0.211707\tvalid_0's amex_metric: 0.804352\n",
      "[12800]\tvalid_0's binary_logloss: 0.21174\tvalid_0's amex_metric: 0.804687\n",
      "Early stopping, best iteration is:\n",
      "[6877]\tvalid_0's binary_logloss: 0.210615\tvalid_0's amex_metric: 0.803992\n",
      "ready to Predict validation\n",
      "ready to Add to out of folds array\n",
      "ready to Predict the test set\n",
      "Our fold 2 CV score is 0.8039924851947979\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 3 with 1365 features...\n",
      "[LightGBM] [Info] Number of positive: 103975, number of negative: 297574\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.792221 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224174\n",
      "[LightGBM] [Info] Number of data points in the train set: 401549, number of used features: 1357\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258935 -> initscore=-1.051512\n",
      "[LightGBM] [Info] Start training from score -1.051512\n",
      "Training until validation scores don't improve for 6000 rounds\n",
      "Early stopping, longdistance iteration is:\n",
      "[1]\t1\t0.705248066037198\t0.7219434883697684\n",
      "Early stopping, longdistance iteration is:\n",
      "[2]\t13\t0.7472326446657477\t0.7482092151901208\n",
      "Early stopping, longdistance iteration is:\n",
      "[6]\t19\t0.7482092151901208\t0.7483367826273235\n",
      "Early stopping, longdistance iteration is:\n",
      "[11]\t40\t0.7532875004535191\t0.7536868182054393\n",
      "[100]\tvalid_0's binary_logloss: 0.379672\tvalid_0's amex_metric: 0.75852\n",
      "[200]\tvalid_0's binary_logloss: 0.303732\tvalid_0's amex_metric: 0.764602\n",
      "Early stopping, longdistance iteration is:\n",
      "[14]\t247\t0.7667804650175754\t0.7669176342562573\n",
      "[300]\tvalid_0's binary_logloss: 0.26727\tvalid_0's amex_metric: 0.769664\n",
      "[400]\tvalid_0's binary_logloss: 0.248343\tvalid_0's amex_metric: 0.774922\n",
      "Early stopping, longdistance iteration is:\n",
      "[15]\t447\t0.7761424040913878\t0.7762378329392859\n",
      "Early stopping, longdistance iteration is:\n",
      "[18]\t479\t0.7766341387148963\t0.7768496702828918\n",
      "[500]\tvalid_0's binary_logloss: 0.237731\tvalid_0's amex_metric: 0.777361\n",
      "Early stopping, longdistance iteration is:\n",
      "[24]\t596\t0.7798087711049906\t0.7800019000945633\n",
      "[600]\tvalid_0's binary_logloss: 0.23158\tvalid_0's amex_metric: 0.779819\n",
      "[700]\tvalid_0's binary_logloss: 0.227703\tvalid_0's amex_metric: 0.782042\n",
      "Early stopping, longdistance iteration is:\n",
      "[27]\t790\t0.7841806246698406\t0.7843078510614292\n",
      "[800]\tvalid_0's binary_logloss: 0.225156\tvalid_0's amex_metric: 0.784119\n",
      "[900]\tvalid_0's binary_logloss: 0.223355\tvalid_0's amex_metric: 0.785845\n",
      "[1000]\tvalid_0's binary_logloss: 0.222049\tvalid_0's amex_metric: 0.787654\n",
      "Early stopping, longdistance iteration is:\n",
      "[44]\t1097\t0.7882618721534477\t0.7883922803530643\n",
      "[1100]\tvalid_0's binary_logloss: 0.221017\tvalid_0's amex_metric: 0.788331\n",
      "[1200]\tvalid_0's binary_logloss: 0.220227\tvalid_0's amex_metric: 0.788509\n",
      "[1300]\tvalid_0's binary_logloss: 0.219595\tvalid_0's amex_metric: 0.789484\n",
      "[1400]\tvalid_0's binary_logloss: 0.219079\tvalid_0's amex_metric: 0.789783\n",
      "[1500]\tvalid_0's binary_logloss: 0.218621\tvalid_0's amex_metric: 0.791781\n",
      "[1600]\tvalid_0's binary_logloss: 0.218225\tvalid_0's amex_metric: 0.791982\n",
      "[1700]\tvalid_0's binary_logloss: 0.217905\tvalid_0's amex_metric: 0.791714\n",
      "Early stopping, longdistance iteration is:\n",
      "[146]\t1709\t0.7924092205222321\t0.7924302845465199\n",
      "[1800]\tvalid_0's binary_logloss: 0.217603\tvalid_0's amex_metric: 0.792357\n",
      "[1900]\tvalid_0's binary_logloss: 0.217326\tvalid_0's amex_metric: 0.792487\n",
      "[2000]\tvalid_0's binary_logloss: 0.217129\tvalid_0's amex_metric: 0.792183\n",
      "[2100]\tvalid_0's binary_logloss: 0.216949\tvalid_0's amex_metric: 0.792347\n",
      "[2200]\tvalid_0's binary_logloss: 0.216775\tvalid_0's amex_metric: 0.79254\n",
      "Early stopping, longdistance iteration is:\n",
      "[324]\t2210\t0.7928797529652749\t0.7928818432358715\n",
      "[2300]\tvalid_0's binary_logloss: 0.216658\tvalid_0's amex_metric: 0.792948\n",
      "[2400]\tvalid_0's binary_logloss: 0.216508\tvalid_0's amex_metric: 0.793034\n",
      "[2500]\tvalid_0's binary_logloss: 0.216397\tvalid_0's amex_metric: 0.793475\n",
      "[2600]\tvalid_0's binary_logloss: 0.216286\tvalid_0's amex_metric: 0.792703\n",
      "[2700]\tvalid_0's binary_logloss: 0.216218\tvalid_0's amex_metric: 0.792928\n",
      "[2800]\tvalid_0's binary_logloss: 0.216131\tvalid_0's amex_metric: 0.792654\n",
      "[2900]\tvalid_0's binary_logloss: 0.216024\tvalid_0's amex_metric: 0.792794\n",
      "[3000]\tvalid_0's binary_logloss: 0.215966\tvalid_0's amex_metric: 0.793051\n",
      "[3100]\tvalid_0's binary_logloss: 0.215869\tvalid_0's amex_metric: 0.792884\n",
      "[3200]\tvalid_0's binary_logloss: 0.215786\tvalid_0's amex_metric: 0.792914\n",
      "[3300]\tvalid_0's binary_logloss: 0.215737\tvalid_0's amex_metric: 0.792966\n",
      "[3400]\tvalid_0's binary_logloss: 0.215672\tvalid_0's amex_metric: 0.79319\n",
      "[3500]\tvalid_0's binary_logloss: 0.215635\tvalid_0's amex_metric: 0.793304\n",
      "Early stopping, longdistance iteration is:\n",
      "[1047]\t3570\t0.7938897222844139\t0.7938906119470095\n",
      "[3600]\tvalid_0's binary_logloss: 0.215594\tvalid_0's amex_metric: 0.794028\n",
      "[3700]\tvalid_0's binary_logloss: 0.215528\tvalid_0's amex_metric: 0.793682\n",
      "[3800]\tvalid_0's binary_logloss: 0.215474\tvalid_0's amex_metric: 0.793702\n",
      "[3900]\tvalid_0's binary_logloss: 0.215443\tvalid_0's amex_metric: 0.794184\n",
      "[4000]\tvalid_0's binary_logloss: 0.215378\tvalid_0's amex_metric: 0.79404\n",
      "[4100]\tvalid_0's binary_logloss: 0.215325\tvalid_0's amex_metric: 0.794295\n",
      "[4200]\tvalid_0's binary_logloss: 0.215311\tvalid_0's amex_metric: 0.794028\n",
      "[4300]\tvalid_0's binary_logloss: 0.215268\tvalid_0's amex_metric: 0.794448\n",
      "[4400]\tvalid_0's binary_logloss: 0.215223\tvalid_0's amex_metric: 0.794296\n",
      "[4500]\tvalid_0's binary_logloss: 0.215179\tvalid_0's amex_metric: 0.794548\n",
      "[4600]\tvalid_0's binary_logloss: 0.215132\tvalid_0's amex_metric: 0.794328\n",
      "[4700]\tvalid_0's binary_logloss: 0.215125\tvalid_0's amex_metric: 0.794938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4800]\tvalid_0's binary_logloss: 0.215067\tvalid_0's amex_metric: 0.794726\n",
      "[4900]\tvalid_0's binary_logloss: 0.215039\tvalid_0's amex_metric: 0.794131\n",
      "[5000]\tvalid_0's binary_logloss: 0.215004\tvalid_0's amex_metric: 0.794986\n",
      "[5100]\tvalid_0's binary_logloss: 0.215004\tvalid_0's amex_metric: 0.794549\n",
      "[5200]\tvalid_0's binary_logloss: 0.214982\tvalid_0's amex_metric: 0.794793\n",
      "[5300]\tvalid_0's binary_logloss: 0.214945\tvalid_0's amex_metric: 0.794676\n",
      "[5400]\tvalid_0's binary_logloss: 0.214921\tvalid_0's amex_metric: 0.794517\n",
      "[5500]\tvalid_0's binary_logloss: 0.214904\tvalid_0's amex_metric: 0.794726\n",
      "[5600]\tvalid_0's binary_logloss: 0.21489\tvalid_0's amex_metric: 0.795004\n",
      "[5700]\tvalid_0's binary_logloss: 0.21487\tvalid_0's amex_metric: 0.794976\n",
      "[5800]\tvalid_0's binary_logloss: 0.214857\tvalid_0's amex_metric: 0.795051\n",
      "[5900]\tvalid_0's binary_logloss: 0.214847\tvalid_0's amex_metric: 0.794819\n",
      "[6000]\tvalid_0's binary_logloss: 0.214837\tvalid_0's amex_metric: 0.794592\n",
      "[6100]\tvalid_0's binary_logloss: 0.214836\tvalid_0's amex_metric: 0.794193\n",
      "[6200]\tvalid_0's binary_logloss: 0.214824\tvalid_0's amex_metric: 0.79457\n",
      "[6300]\tvalid_0's binary_logloss: 0.214843\tvalid_0's amex_metric: 0.794939\n",
      "[6400]\tvalid_0's binary_logloss: 0.214831\tvalid_0's amex_metric: 0.795016\n",
      "[6500]\tvalid_0's binary_logloss: 0.214834\tvalid_0's amex_metric: 0.795322\n",
      "[6600]\tvalid_0's binary_logloss: 0.214827\tvalid_0's amex_metric: 0.794822\n",
      "[6700]\tvalid_0's binary_logloss: 0.21485\tvalid_0's amex_metric: 0.794819\n",
      "[6800]\tvalid_0's binary_logloss: 0.214856\tvalid_0's amex_metric: 0.794989\n",
      "[6900]\tvalid_0's binary_logloss: 0.214853\tvalid_0's amex_metric: 0.794655\n",
      "[7000]\tvalid_0's binary_logloss: 0.214815\tvalid_0's amex_metric: 0.794772\n",
      "[7100]\tvalid_0's binary_logloss: 0.214822\tvalid_0's amex_metric: 0.794639\n",
      "[7200]\tvalid_0's binary_logloss: 0.214857\tvalid_0's amex_metric: 0.794431\n",
      "[7300]\tvalid_0's binary_logloss: 0.214872\tvalid_0's amex_metric: 0.794364\n",
      "[7400]\tvalid_0's binary_logloss: 0.214893\tvalid_0's amex_metric: 0.794763\n",
      "[7500]\tvalid_0's binary_logloss: 0.214886\tvalid_0's amex_metric: 0.794771\n",
      "[7600]\tvalid_0's binary_logloss: 0.214903\tvalid_0's amex_metric: 0.794769\n",
      "[7700]\tvalid_0's binary_logloss: 0.214935\tvalid_0's amex_metric: 0.795066\n",
      "[7800]\tvalid_0's binary_logloss: 0.214957\tvalid_0's amex_metric: 0.795131\n",
      "[7900]\tvalid_0's binary_logloss: 0.21496\tvalid_0's amex_metric: 0.795339\n",
      "[8000]\tvalid_0's binary_logloss: 0.21496\tvalid_0's amex_metric: 0.794841\n",
      "[8100]\tvalid_0's binary_logloss: 0.214973\tvalid_0's amex_metric: 0.794977\n",
      "[8200]\tvalid_0's binary_logloss: 0.21499\tvalid_0's amex_metric: 0.79478\n",
      "[8300]\tvalid_0's binary_logloss: 0.215005\tvalid_0's amex_metric: 0.795053\n",
      "[8400]\tvalid_0's binary_logloss: 0.214975\tvalid_0's amex_metric: 0.795066\n",
      "[8500]\tvalid_0's binary_logloss: 0.214995\tvalid_0's amex_metric: 0.795369\n",
      "[8600]\tvalid_0's binary_logloss: 0.215002\tvalid_0's amex_metric: 0.795103\n",
      "[8700]\tvalid_0's binary_logloss: 0.215023\tvalid_0's amex_metric: 0.794864\n",
      "[8800]\tvalid_0's binary_logloss: 0.215043\tvalid_0's amex_metric: 0.794731\n",
      "[8900]\tvalid_0's binary_logloss: 0.215067\tvalid_0's amex_metric: 0.794694\n",
      "[9000]\tvalid_0's binary_logloss: 0.215107\tvalid_0's amex_metric: 0.794689\n",
      "[9100]\tvalid_0's binary_logloss: 0.215159\tvalid_0's amex_metric: 0.794986\n",
      "[9200]\tvalid_0's binary_logloss: 0.215144\tvalid_0's amex_metric: 0.795097\n",
      "Early stopping, longdistance iteration is:\n",
      "[1524]\t9214\t0.7956023096195554\t0.7956676072147186\n",
      "[9300]\tvalid_0's binary_logloss: 0.215182\tvalid_0's amex_metric: 0.794891\n",
      "[9400]\tvalid_0's binary_logloss: 0.215198\tvalid_0's amex_metric: 0.794693\n",
      "[9500]\tvalid_0's binary_logloss: 0.215213\tvalid_0's amex_metric: 0.794695\n",
      "[9600]\tvalid_0's binary_logloss: 0.215235\tvalid_0's amex_metric: 0.795034\n",
      "[9700]\tvalid_0's binary_logloss: 0.21528\tvalid_0's amex_metric: 0.794559\n",
      "[9800]\tvalid_0's binary_logloss: 0.215283\tvalid_0's amex_metric: 0.794665\n",
      "[9900]\tvalid_0's binary_logloss: 0.215326\tvalid_0's amex_metric: 0.794997\n",
      "[10000]\tvalid_0's binary_logloss: 0.215314\tvalid_0's amex_metric: 0.794705\n",
      "[10100]\tvalid_0's binary_logloss: 0.215351\tvalid_0's amex_metric: 0.794737\n",
      "[10200]\tvalid_0's binary_logloss: 0.215374\tvalid_0's amex_metric: 0.795448\n",
      "[10300]\tvalid_0's binary_logloss: 0.215393\tvalid_0's amex_metric: 0.795383\n",
      "[10400]\tvalid_0's binary_logloss: 0.215407\tvalid_0's amex_metric: 0.795185\n",
      "[10500]\tvalid_0's binary_logloss: 0.215446\tvalid_0's amex_metric: 0.794945\n",
      "[10600]\tvalid_0's binary_logloss: 0.215446\tvalid_0's amex_metric: 0.795019\n",
      "[10700]\tvalid_0's binary_logloss: 0.215494\tvalid_0's amex_metric: 0.794642\n",
      "[10800]\tvalid_0's binary_logloss: 0.215549\tvalid_0's amex_metric: 0.79474\n",
      "[10900]\tvalid_0's binary_logloss: 0.215566\tvalid_0's amex_metric: 0.794507\n",
      "[11000]\tvalid_0's binary_logloss: 0.215599\tvalid_0's amex_metric: 0.794643\n",
      "[11100]\tvalid_0's binary_logloss: 0.215639\tvalid_0's amex_metric: 0.794607\n",
      "[11200]\tvalid_0's binary_logloss: 0.215689\tvalid_0's amex_metric: 0.7944\n",
      "[11300]\tvalid_0's binary_logloss: 0.215697\tvalid_0's amex_metric: 0.794539\n",
      "[11400]\tvalid_0's binary_logloss: 0.215751\tvalid_0's amex_metric: 0.794565\n",
      "[11500]\tvalid_0's binary_logloss: 0.215748\tvalid_0's amex_metric: 0.794815\n",
      "[11600]\tvalid_0's binary_logloss: 0.215802\tvalid_0's amex_metric: 0.794942\n",
      "[11700]\tvalid_0's binary_logloss: 0.215819\tvalid_0's amex_metric: 0.794911\n",
      "[11800]\tvalid_0's binary_logloss: 0.215848\tvalid_0's amex_metric: 0.794744\n",
      "[11900]\tvalid_0's binary_logloss: 0.215874\tvalid_0's amex_metric: 0.795085\n",
      "[12000]\tvalid_0's binary_logloss: 0.215927\tvalid_0's amex_metric: 0.794711\n",
      "[12100]\tvalid_0's binary_logloss: 0.215965\tvalid_0's amex_metric: 0.794713\n",
      "[12200]\tvalid_0's binary_logloss: 0.215997\tvalid_0's amex_metric: 0.794716\n",
      "[12300]\tvalid_0's binary_logloss: 0.216038\tvalid_0's amex_metric: 0.794816\n",
      "[12400]\tvalid_0's binary_logloss: 0.216088\tvalid_0's amex_metric: 0.79515\n",
      "[12500]\tvalid_0's binary_logloss: 0.216112\tvalid_0's amex_metric: 0.795394\n",
      "Early stopping, longdistance iteration is:\n",
      "[2309]\t12546\t0.795685426289942\t0.7957340673022129\n",
      "[12600]\tvalid_0's binary_logloss: 0.216118\tvalid_0's amex_metric: 0.795403\n",
      "[12700]\tvalid_0's binary_logloss: 0.216181\tvalid_0's amex_metric: 0.795433\n",
      "[12800]\tvalid_0's binary_logloss: 0.21624\tvalid_0's amex_metric: 0.795362\n",
      "[12900]\tvalid_0's binary_logloss: 0.216302\tvalid_0's amex_metric: 0.795354\n",
      "Early stopping, best iteration is:\n",
      "[6998]\tvalid_0's binary_logloss: 0.214812\tvalid_0's amex_metric: 0.794841\n",
      "ready to Predict validation\n",
      "ready to Add to out of folds array\n",
      "ready to Predict the test set\n",
      "Our fold 3 CV score is 0.7948408141678189\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 4 with 1365 features...\n",
      "[LightGBM] [Info] Number of positive: 103975, number of negative: 297574\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.400420 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 224132\n",
      "[LightGBM] [Info] Number of data points in the train set: 401549, number of used features: 1357\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258935 -> initscore=-1.051512\n",
      "[LightGBM] [Info] Start training from score -1.051512\n",
      "Training until validation scores don't improve for 6000 rounds\n",
      "Early stopping, longdistance iteration is:\n",
      "[1]\t1\t0.7100666276465497\t0.7220550627656931\n",
      "Early stopping, longdistance iteration is:\n",
      "[2]\t13\t0.7461144219735562\t0.7469242298605656\n",
      "Early stopping, longdistance iteration is:\n",
      "[3]\t18\t0.7477567750805703\t0.7478345176804703\n",
      "Early stopping, longdistance iteration is:\n",
      "[4]\t23\t0.7484007137379873\t0.7499157015536351\n",
      "Early stopping, longdistance iteration is:\n",
      "[8]\t45\t0.7523100331962878\t0.7523209246207926\n",
      "Early stopping, longdistance iteration is:\n",
      "[9]\t56\t0.7535186038221725\t0.7536302364502693\n",
      "[100]\tvalid_0's binary_logloss: 0.380009\tvalid_0's amex_metric: 0.757864\n",
      "Early stopping, longdistance iteration is:\n",
      "[16]\t136\t0.7591964815579657\t0.7593511610878636\n",
      "Early stopping, longdistance iteration is:\n",
      "[19]\t182\t0.7615607183222439\t0.7617082518502393\n",
      "[200]\tvalid_0's binary_logloss: 0.30445\tvalid_0's amex_metric: 0.76284\n",
      "[300]\tvalid_0's binary_logloss: 0.268397\tvalid_0's amex_metric: 0.766897\n",
      "[400]\tvalid_0's binary_logloss: 0.249585\tvalid_0's amex_metric: 0.770976\n",
      "[500]\tvalid_0's binary_logloss: 0.239236\tvalid_0's amex_metric: 0.775082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[600]\tvalid_0's binary_logloss: 0.233246\tvalid_0's amex_metric: 0.778474\n",
      "[700]\tvalid_0's binary_logloss: 0.229492\tvalid_0's amex_metric: 0.781269\n",
      "Early stopping, longdistance iteration is:\n",
      "[37]\t799\t0.7828702178643777\t0.7829724157227376\n",
      "[800]\tvalid_0's binary_logloss: 0.227058\tvalid_0's amex_metric: 0.782972\n",
      "[900]\tvalid_0's binary_logloss: 0.225327\tvalid_0's amex_metric: 0.785319\n",
      "[1000]\tvalid_0's binary_logloss: 0.224071\tvalid_0's amex_metric: 0.786486\n",
      "[1100]\tvalid_0's binary_logloss: 0.223096\tvalid_0's amex_metric: 0.788158\n",
      "[1200]\tvalid_0's binary_logloss: 0.222395\tvalid_0's amex_metric: 0.788929\n",
      "Early stopping, longdistance iteration is:\n",
      "[101]\t1272\t0.789002733362089\t0.7890590095008057\n",
      "[1300]\tvalid_0's binary_logloss: 0.221841\tvalid_0's amex_metric: 0.789405\n",
      "[1400]\tvalid_0's binary_logloss: 0.221334\tvalid_0's amex_metric: 0.790011\n",
      "[1500]\tvalid_0's binary_logloss: 0.220916\tvalid_0's amex_metric: 0.790525\n",
      "[1600]\tvalid_0's binary_logloss: 0.220553\tvalid_0's amex_metric: 0.791226\n",
      "[1700]\tvalid_0's binary_logloss: 0.220255\tvalid_0's amex_metric: 0.792008\n",
      "[1800]\tvalid_0's binary_logloss: 0.219963\tvalid_0's amex_metric: 0.792143\n",
      "[1900]\tvalid_0's binary_logloss: 0.219742\tvalid_0's amex_metric: 0.793165\n",
      "[2000]\tvalid_0's binary_logloss: 0.219543\tvalid_0's amex_metric: 0.792899\n",
      "[2100]\tvalid_0's binary_logloss: 0.219351\tvalid_0's amex_metric: 0.792698\n",
      "Early stopping, longdistance iteration is:\n",
      "[276]\t2175\t0.7931654412528998\t0.7932227009171444\n",
      "[2200]\tvalid_0's binary_logloss: 0.219179\tvalid_0's amex_metric: 0.792898\n",
      "[2300]\tvalid_0's binary_logloss: 0.219041\tvalid_0's amex_metric: 0.793249\n",
      "[2400]\tvalid_0's binary_logloss: 0.218939\tvalid_0's amex_metric: 0.79322\n",
      "[2500]\tvalid_0's binary_logloss: 0.218801\tvalid_0's amex_metric: 0.793939\n",
      "[2600]\tvalid_0's binary_logloss: 0.218695\tvalid_0's amex_metric: 0.794243\n",
      "[2700]\tvalid_0's binary_logloss: 0.218573\tvalid_0's amex_metric: 0.793987\n",
      "[2800]\tvalid_0's binary_logloss: 0.218491\tvalid_0's amex_metric: 0.793948\n",
      "[2900]\tvalid_0's binary_logloss: 0.218408\tvalid_0's amex_metric: 0.794651\n",
      "[3000]\tvalid_0's binary_logloss: 0.21833\tvalid_0's amex_metric: 0.794883\n",
      "[3100]\tvalid_0's binary_logloss: 0.218241\tvalid_0's amex_metric: 0.79488\n",
      "[3200]\tvalid_0's binary_logloss: 0.218182\tvalid_0's amex_metric: 0.794968\n",
      "[3300]\tvalid_0's binary_logloss: 0.218091\tvalid_0's amex_metric: 0.795472\n",
      "[3400]\tvalid_0's binary_logloss: 0.218052\tvalid_0's amex_metric: 0.794982\n",
      "[3500]\tvalid_0's binary_logloss: 0.218009\tvalid_0's amex_metric: 0.795198\n",
      "Early stopping, longdistance iteration is:\n",
      "[468]\t3526\t0.7954744594739316\t0.7954756867435869\n",
      "[3600]\tvalid_0's binary_logloss: 0.217965\tvalid_0's amex_metric: 0.795487\n",
      "[3700]\tvalid_0's binary_logloss: 0.21792\tvalid_0's amex_metric: 0.795472\n",
      "[3800]\tvalid_0's binary_logloss: 0.217878\tvalid_0's amex_metric: 0.795521\n",
      "[3900]\tvalid_0's binary_logloss: 0.217826\tvalid_0's amex_metric: 0.795712\n",
      "[4000]\tvalid_0's binary_logloss: 0.217784\tvalid_0's amex_metric: 0.795426\n",
      "[4100]\tvalid_0's binary_logloss: 0.217758\tvalid_0's amex_metric: 0.795168\n",
      "[4200]\tvalid_0's binary_logloss: 0.217722\tvalid_0's amex_metric: 0.795451\n",
      "[4300]\tvalid_0's binary_logloss: 0.217697\tvalid_0's amex_metric: 0.795063\n",
      "[4400]\tvalid_0's binary_logloss: 0.217667\tvalid_0's amex_metric: 0.795443\n",
      "[4500]\tvalid_0's binary_logloss: 0.217676\tvalid_0's amex_metric: 0.795545\n",
      "[4600]\tvalid_0's binary_logloss: 0.217665\tvalid_0's amex_metric: 0.79572\n",
      "[4700]\tvalid_0's binary_logloss: 0.21765\tvalid_0's amex_metric: 0.795864\n",
      "[4800]\tvalid_0's binary_logloss: 0.217632\tvalid_0's amex_metric: 0.795605\n",
      "[4900]\tvalid_0's binary_logloss: 0.217596\tvalid_0's amex_metric: 0.795518\n",
      "[5000]\tvalid_0's binary_logloss: 0.217598\tvalid_0's amex_metric: 0.795587\n",
      "Early stopping, longdistance iteration is:\n",
      "[1260]\t5091\t0.7960669289659241\t0.7960685489597688\n",
      "[5100]\tvalid_0's binary_logloss: 0.217567\tvalid_0's amex_metric: 0.796036\n",
      "[5200]\tvalid_0's binary_logloss: 0.217555\tvalid_0's amex_metric: 0.795572\n",
      "[5300]\tvalid_0's binary_logloss: 0.217534\tvalid_0's amex_metric: 0.796023\n",
      "[5400]\tvalid_0's binary_logloss: 0.217497\tvalid_0's amex_metric: 0.795839\n",
      "[5500]\tvalid_0's binary_logloss: 0.217484\tvalid_0's amex_metric: 0.795578\n",
      "[5600]\tvalid_0's binary_logloss: 0.217481\tvalid_0's amex_metric: 0.795717\n",
      "[5700]\tvalid_0's binary_logloss: 0.217443\tvalid_0's amex_metric: 0.796105\n",
      "[5800]\tvalid_0's binary_logloss: 0.21743\tvalid_0's amex_metric: 0.796212\n",
      "[5900]\tvalid_0's binary_logloss: 0.217433\tvalid_0's amex_metric: 0.795948\n",
      "[6000]\tvalid_0's binary_logloss: 0.21744\tvalid_0's amex_metric: 0.795748\n",
      "[6100]\tvalid_0's binary_logloss: 0.217437\tvalid_0's amex_metric: 0.795586\n",
      "[6200]\tvalid_0's binary_logloss: 0.217447\tvalid_0's amex_metric: 0.795517\n",
      "[6300]\tvalid_0's binary_logloss: 0.217456\tvalid_0's amex_metric: 0.795454\n",
      "[6400]\tvalid_0's binary_logloss: 0.217478\tvalid_0's amex_metric: 0.79555\n",
      "[6500]\tvalid_0's binary_logloss: 0.217466\tvalid_0's amex_metric: 0.795155\n",
      "[6600]\tvalid_0's binary_logloss: 0.217437\tvalid_0's amex_metric: 0.794968\n",
      "[6700]\tvalid_0's binary_logloss: 0.21743\tvalid_0's amex_metric: 0.794841\n",
      "[6800]\tvalid_0's binary_logloss: 0.21747\tvalid_0's amex_metric: 0.79507\n",
      "[6900]\tvalid_0's binary_logloss: 0.217485\tvalid_0's amex_metric: 0.794769\n",
      "[7000]\tvalid_0's binary_logloss: 0.217456\tvalid_0's amex_metric: 0.795152\n",
      "[7100]\tvalid_0's binary_logloss: 0.217451\tvalid_0's amex_metric: 0.794654\n",
      "[7200]\tvalid_0's binary_logloss: 0.217493\tvalid_0's amex_metric: 0.795119\n",
      "[7300]\tvalid_0's binary_logloss: 0.21751\tvalid_0's amex_metric: 0.79515\n",
      "[7400]\tvalid_0's binary_logloss: 0.217528\tvalid_0's amex_metric: 0.794947\n",
      "[7500]\tvalid_0's binary_logloss: 0.217544\tvalid_0's amex_metric: 0.794948\n",
      "[7600]\tvalid_0's binary_logloss: 0.217557\tvalid_0's amex_metric: 0.794947\n",
      "[7700]\tvalid_0's binary_logloss: 0.217568\tvalid_0's amex_metric: 0.794647\n",
      "[7800]\tvalid_0's binary_logloss: 0.217585\tvalid_0's amex_metric: 0.794883\n",
      "[7900]\tvalid_0's binary_logloss: 0.21758\tvalid_0's amex_metric: 0.794959\n",
      "[8000]\tvalid_0's binary_logloss: 0.217598\tvalid_0's amex_metric: 0.79533\n",
      "[8100]\tvalid_0's binary_logloss: 0.217599\tvalid_0's amex_metric: 0.795302\n",
      "[8200]\tvalid_0's binary_logloss: 0.21761\tvalid_0's amex_metric: 0.795272\n",
      "[8300]\tvalid_0's binary_logloss: 0.217635\tvalid_0's amex_metric: 0.795207\n",
      "[8400]\tvalid_0's binary_logloss: 0.217639\tvalid_0's amex_metric: 0.795448\n",
      "[8500]\tvalid_0's binary_logloss: 0.217655\tvalid_0's amex_metric: 0.795147\n",
      "[8600]\tvalid_0's binary_logloss: 0.217663\tvalid_0's amex_metric: 0.795423\n",
      "[8700]\tvalid_0's binary_logloss: 0.217697\tvalid_0's amex_metric: 0.795691\n",
      "[8800]\tvalid_0's binary_logloss: 0.217734\tvalid_0's amex_metric: 0.795822\n",
      "[8900]\tvalid_0's binary_logloss: 0.217744\tvalid_0's amex_metric: 0.79576\n",
      "[9000]\tvalid_0's binary_logloss: 0.217782\tvalid_0's amex_metric: 0.796095\n",
      "[9100]\tvalid_0's binary_logloss: 0.217801\tvalid_0's amex_metric: 0.795823\n",
      "[9200]\tvalid_0's binary_logloss: 0.217836\tvalid_0's amex_metric: 0.79582\n",
      "[9300]\tvalid_0's binary_logloss: 0.217866\tvalid_0's amex_metric: 0.796122\n",
      "[9400]\tvalid_0's binary_logloss: 0.217882\tvalid_0's amex_metric: 0.795588\n",
      "[9500]\tvalid_0's binary_logloss: 0.217908\tvalid_0's amex_metric: 0.795386\n",
      "[9600]\tvalid_0's binary_logloss: 0.217942\tvalid_0's amex_metric: 0.795347\n",
      "[9700]\tvalid_0's binary_logloss: 0.217974\tvalid_0's amex_metric: 0.795245\n",
      "[9800]\tvalid_0's binary_logloss: 0.218013\tvalid_0's amex_metric: 0.795378\n",
      "[9900]\tvalid_0's binary_logloss: 0.218048\tvalid_0's amex_metric: 0.795414\n",
      "[10000]\tvalid_0's binary_logloss: 0.218085\tvalid_0's amex_metric: 0.79575\n",
      "[10100]\tvalid_0's binary_logloss: 0.218108\tvalid_0's amex_metric: 0.795417\n",
      "[10200]\tvalid_0's binary_logloss: 0.218122\tvalid_0's amex_metric: 0.795688\n",
      "[10300]\tvalid_0's binary_logloss: 0.218159\tvalid_0's amex_metric: 0.795347\n",
      "[10400]\tvalid_0's binary_logloss: 0.218198\tvalid_0's amex_metric: 0.79538\n",
      "[10500]\tvalid_0's binary_logloss: 0.218212\tvalid_0's amex_metric: 0.795418\n",
      "[10600]\tvalid_0's binary_logloss: 0.218273\tvalid_0's amex_metric: 0.795683\n",
      "[10700]\tvalid_0's binary_logloss: 0.21831\tvalid_0's amex_metric: 0.795076\n",
      "[10800]\tvalid_0's binary_logloss: 0.218368\tvalid_0's amex_metric: 0.795711\n",
      "[10900]\tvalid_0's binary_logloss: 0.218401\tvalid_0's amex_metric: 0.795545\n",
      "[11000]\tvalid_0's binary_logloss: 0.218441\tvalid_0's amex_metric: 0.795512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11100]\tvalid_0's binary_logloss: 0.218487\tvalid_0's amex_metric: 0.795375\n",
      "[11200]\tvalid_0's binary_logloss: 0.21852\tvalid_0's amex_metric: 0.795677\n",
      "[11300]\tvalid_0's binary_logloss: 0.218555\tvalid_0's amex_metric: 0.79524\n",
      "Early stopping, best iteration is:\n",
      "[5331]\tvalid_0's binary_logloss: 0.217507\tvalid_0's amex_metric: 0.796505\n",
      "ready to Predict validation\n",
      "ready to Add to out of folds array\n",
      "ready to Predict the test set\n",
      "Our fold 4 CV score is 0.7965046172512233\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 5 with 1365 features...\n",
      "[LightGBM] [Info] Number of positive: 103974, number of negative: 297575\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.352333 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 224112\n",
      "[LightGBM] [Info] Number of data points in the train set: 401549, number of used features: 1357\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258932 -> initscore=-1.051525\n",
      "[LightGBM] [Info] Start training from score -1.051525\n",
      "Training until validation scores don't improve for 6000 rounds\n",
      "Early stopping, longdistance iteration is:\n",
      "[1]\t1\t0.7086901292355089\t0.7236087465297909\n",
      "Early stopping, longdistance iteration is:\n",
      "[2]\t7\t0.7455280641555591\t0.7467710021491514\n",
      "Early stopping, longdistance iteration is:\n",
      "[3]\t16\t0.7507807803345344\t0.751258423074898\n",
      "Early stopping, longdistance iteration is:\n",
      "[7]\t34\t0.7564752473639459\t0.7565355672008152\n",
      "Early stopping, longdistance iteration is:\n",
      "[9]\t52\t0.7587892346920243\t0.7589051200711935\n",
      "[100]\tvalid_0's binary_logloss: 0.379038\tvalid_0's amex_metric: 0.760728\n",
      "Early stopping, longdistance iteration is:\n",
      "[10]\t106\t0.7617571295230705\t0.7617841022823704\n",
      "Early stopping, longdistance iteration is:\n",
      "[21]\t154\t0.7640672819555853\t0.7642037593359357\n",
      "[200]\tvalid_0's binary_logloss: 0.302944\tvalid_0's amex_metric: 0.765618\n",
      "[300]\tvalid_0's binary_logloss: 0.266671\tvalid_0's amex_metric: 0.769716\n",
      "[400]\tvalid_0's binary_logloss: 0.247714\tvalid_0's amex_metric: 0.772394\n",
      "[500]\tvalid_0's binary_logloss: 0.237232\tvalid_0's amex_metric: 0.775168\n",
      "[600]\tvalid_0's binary_logloss: 0.231115\tvalid_0's amex_metric: 0.778381\n",
      "[700]\tvalid_0's binary_logloss: 0.227266\tvalid_0's amex_metric: 0.781317\n",
      "[800]\tvalid_0's binary_logloss: 0.224737\tvalid_0's amex_metric: 0.78347\n",
      "[900]\tvalid_0's binary_logloss: 0.222968\tvalid_0's amex_metric: 0.784571\n",
      "[1000]\tvalid_0's binary_logloss: 0.221691\tvalid_0's amex_metric: 0.78559\n",
      "Early stopping, longdistance iteration is:\n",
      "[28]\t1052\t0.7865440373266079\t0.786582314696129\n",
      "Early stopping, longdistance iteration is:\n",
      "[30]\t1095\t0.7867477315864353\t0.7867874469625018\n",
      "[1100]\tvalid_0's binary_logloss: 0.22073\tvalid_0's amex_metric: 0.786934\n",
      "[1200]\tvalid_0's binary_logloss: 0.219943\tvalid_0's amex_metric: 0.787674\n",
      "[1300]\tvalid_0's binary_logloss: 0.219317\tvalid_0's amex_metric: 0.78743\n",
      "Early stopping, longdistance iteration is:\n",
      "[128]\t1347\t0.7879519580645704\t0.7879836604092354\n",
      "[1400]\tvalid_0's binary_logloss: 0.218819\tvalid_0's amex_metric: 0.788193\n",
      "[1500]\tvalid_0's binary_logloss: 0.218406\tvalid_0's amex_metric: 0.788426\n",
      "[1600]\tvalid_0's binary_logloss: 0.218059\tvalid_0's amex_metric: 0.789011\n",
      "[1700]\tvalid_0's binary_logloss: 0.217785\tvalid_0's amex_metric: 0.789437\n",
      "[1800]\tvalid_0's binary_logloss: 0.217491\tvalid_0's amex_metric: 0.790177\n",
      "[1900]\tvalid_0's binary_logloss: 0.21727\tvalid_0's amex_metric: 0.790118\n",
      "[2000]\tvalid_0's binary_logloss: 0.217063\tvalid_0's amex_metric: 0.791132\n",
      "[2100]\tvalid_0's binary_logloss: 0.216893\tvalid_0's amex_metric: 0.791052\n",
      "Early stopping, longdistance iteration is:\n",
      "[182]\t2179\t0.7915006654222279\t0.7915308270293897\n",
      "[2200]\tvalid_0's binary_logloss: 0.216754\tvalid_0's amex_metric: 0.791369\n",
      "[2300]\tvalid_0's binary_logloss: 0.216612\tvalid_0's amex_metric: 0.791048\n",
      "[2400]\tvalid_0's binary_logloss: 0.216476\tvalid_0's amex_metric: 0.792405\n",
      "[2500]\tvalid_0's binary_logloss: 0.216356\tvalid_0's amex_metric: 0.791976\n",
      "[2600]\tvalid_0's binary_logloss: 0.216261\tvalid_0's amex_metric: 0.792044\n",
      "Early stopping, longdistance iteration is:\n",
      "[208]\t2613\t0.792610488776113\t0.7926509120694989\n",
      "[2700]\tvalid_0's binary_logloss: 0.216173\tvalid_0's amex_metric: 0.792042\n",
      "[2800]\tvalid_0's binary_logloss: 0.216094\tvalid_0's amex_metric: 0.792811\n",
      "[2900]\tvalid_0's binary_logloss: 0.216007\tvalid_0's amex_metric: 0.792739\n",
      "[3000]\tvalid_0's binary_logloss: 0.215936\tvalid_0's amex_metric: 0.792528\n",
      "[3100]\tvalid_0's binary_logloss: 0.215859\tvalid_0's amex_metric: 0.792789\n",
      "[3200]\tvalid_0's binary_logloss: 0.215806\tvalid_0's amex_metric: 0.792943\n",
      "[3300]\tvalid_0's binary_logloss: 0.21573\tvalid_0's amex_metric: 0.792904\n",
      "Early stopping, longdistance iteration is:\n",
      "[500]\t3316\t0.793185537665489\t0.7932088536438271\n",
      "[3400]\tvalid_0's binary_logloss: 0.215717\tvalid_0's amex_metric: 0.792875\n",
      "[3500]\tvalid_0's binary_logloss: 0.215659\tvalid_0's amex_metric: 0.7932\n",
      "[3600]\tvalid_0's binary_logloss: 0.215595\tvalid_0's amex_metric: 0.79292\n",
      "[3700]\tvalid_0's binary_logloss: 0.21555\tvalid_0's amex_metric: 0.793137\n",
      "[3800]\tvalid_0's binary_logloss: 0.215507\tvalid_0's amex_metric: 0.793455\n",
      "[3900]\tvalid_0's binary_logloss: 0.215447\tvalid_0's amex_metric: 0.792734\n",
      "[4000]\tvalid_0's binary_logloss: 0.215423\tvalid_0's amex_metric: 0.793248\n",
      "[4100]\tvalid_0's binary_logloss: 0.215411\tvalid_0's amex_metric: 0.793354\n",
      "[4200]\tvalid_0's binary_logloss: 0.215405\tvalid_0's amex_metric: 0.793291\n",
      "[4300]\tvalid_0's binary_logloss: 0.215365\tvalid_0's amex_metric: 0.793745\n",
      "Early stopping, longdistance iteration is:\n",
      "[763]\t4302\t0.793818239108788\t0.7939135561373718\n",
      "[4400]\tvalid_0's binary_logloss: 0.21532\tvalid_0's amex_metric: 0.79366\n",
      "[4500]\tvalid_0's binary_logloss: 0.215265\tvalid_0's amex_metric: 0.793447\n",
      "[4600]\tvalid_0's binary_logloss: 0.215261\tvalid_0's amex_metric: 0.793451\n",
      "[4700]\tvalid_0's binary_logloss: 0.21524\tvalid_0's amex_metric: 0.794201\n",
      "[4800]\tvalid_0's binary_logloss: 0.215251\tvalid_0's amex_metric: 0.793798\n",
      "[4900]\tvalid_0's binary_logloss: 0.215254\tvalid_0's amex_metric: 0.793798\n",
      "[5000]\tvalid_0's binary_logloss: 0.215229\tvalid_0's amex_metric: 0.793774\n",
      "[5100]\tvalid_0's binary_logloss: 0.215193\tvalid_0's amex_metric: 0.793789\n",
      "[5200]\tvalid_0's binary_logloss: 0.215166\tvalid_0's amex_metric: 0.793398\n",
      "[5300]\tvalid_0's binary_logloss: 0.215164\tvalid_0's amex_metric: 0.7934\n",
      "[5400]\tvalid_0's binary_logloss: 0.215155\tvalid_0's amex_metric: 0.793203\n",
      "[5500]\tvalid_0's binary_logloss: 0.215128\tvalid_0's amex_metric: 0.793554\n",
      "[5600]\tvalid_0's binary_logloss: 0.215118\tvalid_0's amex_metric: 0.793797\n",
      "[5700]\tvalid_0's binary_logloss: 0.215135\tvalid_0's amex_metric: 0.793657\n",
      "Early stopping, longdistance iteration is:\n",
      "[873]\t5743\t0.7942357618787108\t0.7943285489868345\n",
      "[5800]\tvalid_0's binary_logloss: 0.215153\tvalid_0's amex_metric: 0.794095\n",
      "[5900]\tvalid_0's binary_logloss: 0.215146\tvalid_0's amex_metric: 0.793629\n",
      "[6000]\tvalid_0's binary_logloss: 0.215176\tvalid_0's amex_metric: 0.793119\n",
      "[6100]\tvalid_0's binary_logloss: 0.21516\tvalid_0's amex_metric: 0.79343\n",
      "[6200]\tvalid_0's binary_logloss: 0.215193\tvalid_0's amex_metric: 0.793489\n",
      "[6300]\tvalid_0's binary_logloss: 0.215198\tvalid_0's amex_metric: 0.793289\n",
      "[6400]\tvalid_0's binary_logloss: 0.215221\tvalid_0's amex_metric: 0.793386\n",
      "[6500]\tvalid_0's binary_logloss: 0.21525\tvalid_0's amex_metric: 0.792942\n",
      "[6600]\tvalid_0's binary_logloss: 0.215235\tvalid_0's amex_metric: 0.792845\n",
      "[6700]\tvalid_0's binary_logloss: 0.215243\tvalid_0's amex_metric: 0.793217\n",
      "[6800]\tvalid_0's binary_logloss: 0.215263\tvalid_0's amex_metric: 0.792878\n",
      "[6900]\tvalid_0's binary_logloss: 0.215261\tvalid_0's amex_metric: 0.793186\n",
      "[7000]\tvalid_0's binary_logloss: 0.215264\tvalid_0's amex_metric: 0.792988\n",
      "[7100]\tvalid_0's binary_logloss: 0.215292\tvalid_0's amex_metric: 0.792814\n",
      "[7200]\tvalid_0's binary_logloss: 0.215314\tvalid_0's amex_metric: 0.793419\n",
      "[7300]\tvalid_0's binary_logloss: 0.215345\tvalid_0's amex_metric: 0.793516\n",
      "[7400]\tvalid_0's binary_logloss: 0.215354\tvalid_0's amex_metric: 0.793115\n",
      "[7500]\tvalid_0's binary_logloss: 0.215351\tvalid_0's amex_metric: 0.79312\n",
      "[7600]\tvalid_0's binary_logloss: 0.215332\tvalid_0's amex_metric: 0.793805\n",
      "[7700]\tvalid_0's binary_logloss: 0.21535\tvalid_0's amex_metric: 0.793266\n",
      "[7800]\tvalid_0's binary_logloss: 0.215351\tvalid_0's amex_metric: 0.793234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7900]\tvalid_0's binary_logloss: 0.21537\tvalid_0's amex_metric: 0.792966\n",
      "[8000]\tvalid_0's binary_logloss: 0.215385\tvalid_0's amex_metric: 0.793102\n",
      "[8100]\tvalid_0's binary_logloss: 0.215394\tvalid_0's amex_metric: 0.79297\n",
      "[8200]\tvalid_0's binary_logloss: 0.215411\tvalid_0's amex_metric: 0.793107\n",
      "[8300]\tvalid_0's binary_logloss: 0.215428\tvalid_0's amex_metric: 0.793073\n",
      "[8400]\tvalid_0's binary_logloss: 0.215446\tvalid_0's amex_metric: 0.792667\n",
      "[8500]\tvalid_0's binary_logloss: 0.215438\tvalid_0's amex_metric: 0.792473\n",
      "[8600]\tvalid_0's binary_logloss: 0.215489\tvalid_0's amex_metric: 0.792223\n",
      "[8700]\tvalid_0's binary_logloss: 0.215532\tvalid_0's amex_metric: 0.792453\n",
      "[8800]\tvalid_0's binary_logloss: 0.21556\tvalid_0's amex_metric: 0.792687\n",
      "[8900]\tvalid_0's binary_logloss: 0.215575\tvalid_0's amex_metric: 0.791916\n",
      "[9000]\tvalid_0's binary_logloss: 0.215584\tvalid_0's amex_metric: 0.791686\n",
      "[9100]\tvalid_0's binary_logloss: 0.215599\tvalid_0's amex_metric: 0.792128\n",
      "[9200]\tvalid_0's binary_logloss: 0.215636\tvalid_0's amex_metric: 0.792161\n",
      "[9300]\tvalid_0's binary_logloss: 0.215643\tvalid_0's amex_metric: 0.791962\n",
      "[9400]\tvalid_0's binary_logloss: 0.215681\tvalid_0's amex_metric: 0.791924\n",
      "[9500]\tvalid_0's binary_logloss: 0.215682\tvalid_0's amex_metric: 0.791931\n",
      "[9600]\tvalid_0's binary_logloss: 0.215695\tvalid_0's amex_metric: 0.792572\n",
      "[9700]\tvalid_0's binary_logloss: 0.215729\tvalid_0's amex_metric: 0.792806\n",
      "[9800]\tvalid_0's binary_logloss: 0.215754\tvalid_0's amex_metric: 0.792604\n",
      "[9900]\tvalid_0's binary_logloss: 0.215779\tvalid_0's amex_metric: 0.792235\n",
      "[10000]\tvalid_0's binary_logloss: 0.215832\tvalid_0's amex_metric: 0.792365\n",
      "[10100]\tvalid_0's binary_logloss: 0.215842\tvalid_0's amex_metric: 0.792539\n",
      "[10200]\tvalid_0's binary_logloss: 0.21587\tvalid_0's amex_metric: 0.792437\n",
      "[10300]\tvalid_0's binary_logloss: 0.215887\tvalid_0's amex_metric: 0.792778\n",
      "[10400]\tvalid_0's binary_logloss: 0.215935\tvalid_0's amex_metric: 0.792468\n",
      "[10500]\tvalid_0's binary_logloss: 0.21594\tvalid_0's amex_metric: 0.792512\n",
      "[10600]\tvalid_0's binary_logloss: 0.215958\tvalid_0's amex_metric: 0.792581\n",
      "[10700]\tvalid_0's binary_logloss: 0.216003\tvalid_0's amex_metric: 0.792072\n",
      "[10800]\tvalid_0's binary_logloss: 0.21603\tvalid_0's amex_metric: 0.791939\n",
      "[10900]\tvalid_0's binary_logloss: 0.216094\tvalid_0's amex_metric: 0.791796\n",
      "[11000]\tvalid_0's binary_logloss: 0.216132\tvalid_0's amex_metric: 0.791928\n",
      "[11100]\tvalid_0's binary_logloss: 0.216176\tvalid_0's amex_metric: 0.792129\n",
      "[11200]\tvalid_0's binary_logloss: 0.216205\tvalid_0's amex_metric: 0.791758\n",
      "[11300]\tvalid_0's binary_logloss: 0.216219\tvalid_0's amex_metric: 0.791528\n",
      "[11400]\tvalid_0's binary_logloss: 0.216255\tvalid_0's amex_metric: 0.791628\n",
      "[11500]\tvalid_0's binary_logloss: 0.216282\tvalid_0's amex_metric: 0.792336\n",
      "Early stopping, best iteration is:\n",
      "[5587]\tvalid_0's binary_logloss: 0.215112\tvalid_0's amex_metric: 0.793832\n",
      "ready to Predict validation\n",
      "ready to Add to out of folds array\n",
      "ready to Predict the test set\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import gc\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "import gc\n",
    "import warnings\n",
    "from itertools import combinations\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "import itertools\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ====================================================\n",
    "# Configurations\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    input_dir = \"./\"\n",
    "    seed = 53\n",
    "    n_folds = 8\n",
    "    target = \"target\"\n",
    "    boosting_type = \"53-30000-6600-0.006-8\"\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# Seed everything\n",
    "# ====================================================\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# Read data\n",
    "# ====================================================\n",
    "def read_data():\n",
    "    train = pd.read_parquet(CFG.input_dir + \"train_diff.parquet\")\n",
    "    test = pd.read_parquet(CFG.input_dir + \"test_diff.parquet\")\n",
    "    return train, test\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# Amex metric\n",
    "# ====================================================\n",
    "def amex_metric(y_true, y_pred):\n",
    "    labels = np.transpose(np.array([y_true, y_pred]))\n",
    "    labels = labels[labels[:, 1].argsort()[::-1]]\n",
    "    weights = np.where(labels[:, 0] == 0, 20, 1)\n",
    "    cut_vals = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "    top_four = np.sum(cut_vals[:, 0]) / np.sum(labels[:, 0])\n",
    "    gini = [0, 0]\n",
    "    for i in [1, 0]:\n",
    "        labels = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels = labels[labels[:, i].argsort()[::-1]]\n",
    "        weight = np.where(labels[:, 0] == 0, 20, 1)\n",
    "        weight_random = np.cumsum(weight / np.sum(weight))\n",
    "        total_pos = np.sum(labels[:, 0] * weight)\n",
    "        cum_pos_found = np.cumsum(labels[:, 0] * weight)\n",
    "        lorentz = cum_pos_found / total_pos\n",
    "        gini[i] = np.sum((lorentz - weight_random) * weight)\n",
    "    return 0.5 * (gini[1] / gini[0] + top_four)\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# LGBM amex metric\n",
    "# ====================================================\n",
    "def lgb_amex_metric(y_pred, y_true):\n",
    "    y_true = y_true.get_label()\n",
    "    return \"amex_metric\", amex_metric(y_true, y_pred), True\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "class DartEarlyStopping(object):\n",
    "    def __init__(self, data_name, monitor_metric, stopping_round):\n",
    "        self.data_name = data_name\n",
    "        self.monitor_metric = monitor_metric\n",
    "        self.stopping_round = stopping_round\n",
    "        self.best_score = None\n",
    "        self.best_model = None\n",
    "        self.best_score_list = []\n",
    "        self.best_iter = 0\n",
    "        \n",
    "\n",
    "        self.max = 0\n",
    "        \n",
    "\n",
    "    def _is_higher_score(self, metric_score, is_higher_better):\n",
    "        if self.best_score is None:\n",
    "            return True\n",
    "        return (self.best_score < metric_score) if is_higher_better else (self.best_score > metric_score)\n",
    "\n",
    "    def _deepcopy(self, x):\n",
    "        return pickle.loads(pickle.dumps(x))\n",
    "\n",
    "\n",
    "    def __call__(self, env):\n",
    "        evals = env.evaluation_result_list\n",
    "        for data, metric, score, is_higher_better in evals:\n",
    "            if data != self.data_name or metric != self.monitor_metric:\n",
    "                continue\n",
    "            if not self._is_higher_score(score, is_higher_better):\n",
    "                if env.iteration - self.best_iter > self.stopping_round:\n",
    "                    eval_result_str = '\\t'.join([lgb.callback._format_eval_result(x) for x in self.best_score_list])\n",
    "                    print(f\"Early stopping, best iteration is:\\n[{self.best_iter+1}]\\t{eval_result_str}\") \n",
    "                    print(f\"You can get best model by \\\"DartEarlyStopping.best_model\\\"\")\n",
    "                    raise lgb.callback.EarlyStopException(self.best_iter, self.best_score_list)\n",
    "                return\n",
    "            if (env.iteration - self.best_iter) > self.max:\n",
    "                self.max = env.iteration - self.best_iter\n",
    "                print(f\"Early stopping, longdistance iteration is:\\n[{self.max}]\\t{env.iteration}\\t{self.best_score}\\t{score}\") \n",
    "            self.best_model = self._deepcopy(env.model)\n",
    "            self.best_iter = env.iteration\n",
    "            self.best_score_list = evals\n",
    "            self.best_score = score\n",
    "            return\n",
    "        raise ValueError(\"monitoring metric not found\")\n",
    "\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# Train & Evaluate\n",
    "# ====================================================\n",
    "def train_and_evaluate(train, test):\n",
    "    # Label encode categorical features\n",
    "    cat_features = [\n",
    "        \"B_30\",\n",
    "        \"B_38\",\n",
    "        \"D_114\",\n",
    "        \"D_116\",\n",
    "        \"D_117\",\n",
    "        \"D_120\",\n",
    "        \"D_126\",\n",
    "        \"D_63\",\n",
    "        \"D_64\",\n",
    "        \"D_66\",\n",
    "        \"D_68\",\n",
    "    ]\n",
    "    cat_features = [f\"{cf}_last\" for cf in cat_features]\n",
    "    for cat_col in cat_features:\n",
    "        encoder = LabelEncoder()\n",
    "        train[cat_col] = encoder.fit_transform(train[cat_col])\n",
    "        test[cat_col] = encoder.transform(test[cat_col])\n",
    "    # Round last float features to 2 decimal place\n",
    "    num_cols = list(\n",
    "        train.dtypes[(train.dtypes == \"float32\") | (train.dtypes == \"float64\")].index\n",
    "    )\n",
    "    num_cols = [col for col in num_cols if \"last\" in col]\n",
    "    for col in num_cols:\n",
    "        train[col + \"_round2\"] = train[col].round(2)\n",
    "        test[col + \"_round2\"] = test[col].round(2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Get the difference between last and mean\n",
    "    num_cols = [col for col in train.columns if 'last' in col]\n",
    "    num_cols = [col[:-5] for col in num_cols if 'round' not in col]\n",
    "    for col in num_cols:\n",
    "        try:\n",
    "            train[f'{col}_last_mean_diff'] = train[f'{col}_last'] - train[f'{col}_mean']\n",
    "            test[f'{col}_last_mean_diff'] = test[f'{col}_last'] - test[f'{col}_mean']\n",
    "        except:\n",
    "            pass\n",
    "    # Transform float64 and float32 to float16\n",
    "    num_cols = list(train.dtypes[(train.dtypes == 'float32') | (train.dtypes == 'float64')].index)\n",
    "    for col in tqdm(num_cols):\n",
    "        train[col] = train[col].astype(np.float16)\n",
    "        test[col] = test[col].astype(np.float16)\n",
    "        \n",
    "        \n",
    "    # Get feature list\n",
    "    features = [col for col in train.columns if col not in [\"customer_ID\", CFG.target]]\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': \"binary_logloss\",\n",
    "        'boosting': 'gbdt',\n",
    "        'seed': CFG.seed,\n",
    "        'num_leaves': 100,\n",
    "        'learning_rate': 0.006,\n",
    "        'feature_fraction': 0.20,\n",
    "        'bagging_freq': 10,\n",
    "        'bagging_fraction': 0.50,\n",
    "        'n_jobs': -1,\n",
    "        'lambda_l2': 2,\n",
    "        'min_data_in_leaf': 40\n",
    "        }\n",
    "    \n",
    "    # Create a numpy array to store test predictions\n",
    "    test_predictions = np.zeros(len(test))\n",
    "    # Create a numpy array to store out of folds predictions\n",
    "    oof_predictions = np.zeros(len(train))\n",
    "    kfold = StratifiedKFold(n_splits=CFG.n_folds, shuffle=True, random_state=CFG.seed)\n",
    "    for fold, (trn_ind, val_ind) in enumerate(kfold.split(train, train[CFG.target])):\n",
    "        print(\" \")\n",
    "        print(\"-\" * 50)\n",
    "        print(f\"Training fold {fold} with {len(features)} features...\")\n",
    "        x_train, x_val = train[features].iloc[trn_ind], train[features].iloc[val_ind]\n",
    "#        y_train, y_val = (\n",
    "#            train[CFG.target].iloc[trn_ind],\n",
    "#            train[CFG.target].iloc[val_ind],\n",
    "#        )\n",
    "        y_train, y_val = train[CFG.target].iloc[trn_ind], train[CFG.target].iloc[val_ind]\n",
    "        lgb_train = lgb.Dataset(x_train, y_train, categorical_feature=cat_features)\n",
    "        lgb_valid = lgb.Dataset(x_val, y_val, categorical_feature=cat_features)\n",
    "\n",
    "        es = DartEarlyStopping(\"valid_0\", \"amex_metric\", stopping_round=6000)\n",
    "        model = lgb.train(\n",
    "            params=params,\n",
    "            train_set=lgb_train,\n",
    "            num_boost_round=25000,\n",
    "            valid_sets=[lgb_valid],\n",
    "            early_stopping_rounds=6000,\n",
    "            callbacks=[es],\n",
    "            verbose_eval=100,\n",
    "            feval=lgb_amex_metric,\n",
    "        )\n",
    "\n",
    "        # Save best model\n",
    "        joblib.dump(\n",
    "            model,\n",
    "            f\"lgbm_fold{fold}_{CFG.boosting_type}_seed{CFG.seed}.pkl\",\n",
    "        )\n",
    "        # Predict validation\n",
    "        print(\"ready to Predict validation\")\n",
    "        val_pred = model.predict(x_val)\n",
    "        # Add to out of folds array\n",
    "        print(\"ready to Add to out of folds array\")\n",
    "        oof_predictions[val_ind] = val_pred\n",
    "        # Predict the test set\n",
    "        print(\"ready to Predict the test set\")\n",
    "        test_pred = model.predict(test[features])\n",
    "        test_predictions += test_pred / CFG.n_folds\n",
    "        # Compute fold metric\n",
    "        score = amex_metric(y_val, val_pred)\n",
    "        print(f\"Our fold {fold} CV score is {score}\")\n",
    "        del x_train, x_val, y_train, y_val, lgb_train, lgb_valid\n",
    "        gc.collect()\n",
    "    \n",
    "    # Compute out of folds metric\n",
    "    score = amex_metric(train[CFG.target], oof_predictions)\n",
    "    print(f\"Our out of folds CV score is {score}\")\n",
    "    # Create a dataframe to store out of folds predictions\n",
    "#    oof_df = pd.DataFrame(\n",
    "#        {\n",
    "#            \"customer_ID\": train[\"customer_ID\"],\n",
    "#            \"target\": train[CFG.target],\n",
    "#            \"prediction\": oof_predictions,\n",
    "#        }\n",
    "#    )\n",
    "#    oof_df.to_csv(\n",
    "#        f\"oof_lgbm_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv\",\n",
    "#        index=False,\n",
    "#    )\n",
    "    # Create a dataframe to store test prediction\n",
    "#    test_df = pd.DataFrame(\n",
    "#        {\"customer_ID\": test[\"customer_ID\"], \"prediction\": test_predictions}\n",
    "#    )\n",
    "#    test_df.to_csv(\n",
    "#        f\"test_lgbm_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv\",\n",
    "#        index=False,\n",
    "#    )\n",
    "\n",
    "    oof_df = pd.DataFrame({'customer_ID': train['customer_ID'], 'target': train[CFG.target], 'prediction': oof_predictions})\n",
    "    oof_df.to_csv(f'modifioof_lgbm_{CFG.boosting_type}_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "    # Create a dataframe to store test prediction\n",
    "    test_df = pd.DataFrame({'customer_ID': test['customer_ID'], 'prediction': test_predictions})\n",
    "    test_df.to_csv(f'modifitest_lgbm_{CFG.boosting_type}_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "\n",
    "\n",
    "seed_everything(CFG.seed)\n",
    "train, test = read_data()\n",
    "train_and_evaluate(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb6436f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "import gc\n",
    "import warnings\n",
    "from itertools import combinations\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "import itertools\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ====================================================\n",
    "# Read data\n",
    "# ====================================================\n",
    "def read_data():\n",
    "    train = pd.read_parquet(CFG.input_dir + \"train_diff.parquet\")\n",
    "    test = pd.read_parquet(CFG.input_dir + \"test_diff.parquet\")\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f13ddcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 458913 entries, 0 to 458912\n",
      "Columns: 1097 entries, customer_ID to target\n",
      "dtypes: float32(810), int16(27), int32(22), int64(1), int8(236), object(1)\n",
      "memory usage: 1.6+ GB\n"
     ]
    }
   ],
   "source": [
    "train, test = read_data()\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8165c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    input_dir = \"./\"\n",
    "    seed = 53\n",
    "    n_folds = 8\n",
    "    target = \"target\"\n",
    "    boosting_type = \"53-30000-6600-0.006-8\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9eccd037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32772f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet( \"../baselinedataset/train.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "161182de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5.529435e+06\n",
       "mean     6.105151e-01\n",
       "std      4.029192e-01\n",
       "min      9.192280e-09\n",
       "25%      1.053313e-01\n",
       "50%      8.143328e-01\n",
       "75%      1.002403e+00\n",
       "max      1.010000e+00\n",
       "Name: B_2, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['B_2'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1d4a778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='B_2', ylabel='Count'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set()\n",
    "sns.histplot(train['B_2'], kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4dac017c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9900990192498218"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/(train['B_2']).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94ed2e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>S_2</th>\n",
       "      <th>P_2</th>\n",
       "      <th>D_39</th>\n",
       "      <th>B_1</th>\n",
       "      <th>B_2</th>\n",
       "      <th>R_1</th>\n",
       "      <th>S_3</th>\n",
       "      <th>D_41</th>\n",
       "      <th>B_3</th>\n",
       "      <th>D_42</th>\n",
       "      <th>D_43</th>\n",
       "      <th>D_44</th>\n",
       "      <th>B_4</th>\n",
       "      <th>D_45</th>\n",
       "      <th>B_5</th>\n",
       "      <th>R_2</th>\n",
       "      <th>D_46</th>\n",
       "      <th>D_47</th>\n",
       "      <th>D_48</th>\n",
       "      <th>D_49</th>\n",
       "      <th>B_6</th>\n",
       "      <th>B_7</th>\n",
       "      <th>B_8</th>\n",
       "      <th>D_50</th>\n",
       "      <th>D_51</th>\n",
       "      <th>B_9</th>\n",
       "      <th>R_3</th>\n",
       "      <th>D_52</th>\n",
       "      <th>P_3</th>\n",
       "      <th>B_10</th>\n",
       "      <th>D_53</th>\n",
       "      <th>S_5</th>\n",
       "      <th>B_11</th>\n",
       "      <th>S_6</th>\n",
       "      <th>D_54</th>\n",
       "      <th>R_4</th>\n",
       "      <th>S_7</th>\n",
       "      <th>B_12</th>\n",
       "      <th>S_8</th>\n",
       "      <th>D_55</th>\n",
       "      <th>D_56</th>\n",
       "      <th>B_13</th>\n",
       "      <th>R_5</th>\n",
       "      <th>D_58</th>\n",
       "      <th>S_9</th>\n",
       "      <th>B_14</th>\n",
       "      <th>D_59</th>\n",
       "      <th>D_60</th>\n",
       "      <th>D_61</th>\n",
       "      <th>B_15</th>\n",
       "      <th>S_11</th>\n",
       "      <th>D_62</th>\n",
       "      <th>D_63</th>\n",
       "      <th>D_64</th>\n",
       "      <th>D_65</th>\n",
       "      <th>B_16</th>\n",
       "      <th>B_17</th>\n",
       "      <th>B_18</th>\n",
       "      <th>B_19</th>\n",
       "      <th>D_66</th>\n",
       "      <th>B_20</th>\n",
       "      <th>D_68</th>\n",
       "      <th>S_12</th>\n",
       "      <th>R_6</th>\n",
       "      <th>S_13</th>\n",
       "      <th>B_21</th>\n",
       "      <th>D_69</th>\n",
       "      <th>B_22</th>\n",
       "      <th>D_70</th>\n",
       "      <th>D_71</th>\n",
       "      <th>D_72</th>\n",
       "      <th>S_15</th>\n",
       "      <th>B_23</th>\n",
       "      <th>D_73</th>\n",
       "      <th>P_4</th>\n",
       "      <th>D_74</th>\n",
       "      <th>D_75</th>\n",
       "      <th>D_76</th>\n",
       "      <th>B_24</th>\n",
       "      <th>R_7</th>\n",
       "      <th>D_77</th>\n",
       "      <th>B_25</th>\n",
       "      <th>B_26</th>\n",
       "      <th>D_78</th>\n",
       "      <th>D_79</th>\n",
       "      <th>R_8</th>\n",
       "      <th>R_9</th>\n",
       "      <th>S_16</th>\n",
       "      <th>D_80</th>\n",
       "      <th>R_10</th>\n",
       "      <th>R_11</th>\n",
       "      <th>B_27</th>\n",
       "      <th>D_81</th>\n",
       "      <th>D_82</th>\n",
       "      <th>S_17</th>\n",
       "      <th>R_12</th>\n",
       "      <th>B_28</th>\n",
       "      <th>R_13</th>\n",
       "      <th>D_83</th>\n",
       "      <th>R_14</th>\n",
       "      <th>R_15</th>\n",
       "      <th>D_84</th>\n",
       "      <th>R_16</th>\n",
       "      <th>B_29</th>\n",
       "      <th>B_30</th>\n",
       "      <th>S_18</th>\n",
       "      <th>D_86</th>\n",
       "      <th>D_87</th>\n",
       "      <th>R_17</th>\n",
       "      <th>R_18</th>\n",
       "      <th>D_88</th>\n",
       "      <th>B_31</th>\n",
       "      <th>S_19</th>\n",
       "      <th>R_19</th>\n",
       "      <th>B_32</th>\n",
       "      <th>S_20</th>\n",
       "      <th>R_20</th>\n",
       "      <th>R_21</th>\n",
       "      <th>B_33</th>\n",
       "      <th>D_89</th>\n",
       "      <th>R_22</th>\n",
       "      <th>R_23</th>\n",
       "      <th>D_91</th>\n",
       "      <th>D_92</th>\n",
       "      <th>D_93</th>\n",
       "      <th>D_94</th>\n",
       "      <th>R_24</th>\n",
       "      <th>R_25</th>\n",
       "      <th>D_96</th>\n",
       "      <th>S_22</th>\n",
       "      <th>S_23</th>\n",
       "      <th>S_24</th>\n",
       "      <th>S_25</th>\n",
       "      <th>S_26</th>\n",
       "      <th>D_102</th>\n",
       "      <th>D_103</th>\n",
       "      <th>D_104</th>\n",
       "      <th>D_105</th>\n",
       "      <th>D_106</th>\n",
       "      <th>D_107</th>\n",
       "      <th>B_36</th>\n",
       "      <th>B_37</th>\n",
       "      <th>R_26</th>\n",
       "      <th>R_27</th>\n",
       "      <th>B_38</th>\n",
       "      <th>D_108</th>\n",
       "      <th>D_109</th>\n",
       "      <th>D_110</th>\n",
       "      <th>D_111</th>\n",
       "      <th>B_39</th>\n",
       "      <th>D_112</th>\n",
       "      <th>B_40</th>\n",
       "      <th>S_27</th>\n",
       "      <th>D_113</th>\n",
       "      <th>D_114</th>\n",
       "      <th>D_115</th>\n",
       "      <th>D_116</th>\n",
       "      <th>D_117</th>\n",
       "      <th>D_118</th>\n",
       "      <th>D_119</th>\n",
       "      <th>D_120</th>\n",
       "      <th>D_121</th>\n",
       "      <th>D_122</th>\n",
       "      <th>D_123</th>\n",
       "      <th>D_124</th>\n",
       "      <th>D_125</th>\n",
       "      <th>D_126</th>\n",
       "      <th>D_127</th>\n",
       "      <th>D_128</th>\n",
       "      <th>D_129</th>\n",
       "      <th>B_41</th>\n",
       "      <th>B_42</th>\n",
       "      <th>D_130</th>\n",
       "      <th>D_131</th>\n",
       "      <th>D_132</th>\n",
       "      <th>D_133</th>\n",
       "      <th>R_28</th>\n",
       "      <th>D_134</th>\n",
       "      <th>D_135</th>\n",
       "      <th>D_136</th>\n",
       "      <th>D_137</th>\n",
       "      <th>D_138</th>\n",
       "      <th>D_139</th>\n",
       "      <th>D_140</th>\n",
       "      <th>D_141</th>\n",
       "      <th>D_142</th>\n",
       "      <th>D_143</th>\n",
       "      <th>D_144</th>\n",
       "      <th>D_145</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2017-03-09</td>\n",
       "      <td>0.938469</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008724</td>\n",
       "      <td>1.006838</td>\n",
       "      <td>0.009228</td>\n",
       "      <td>0.124035</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.708906</td>\n",
       "      <td>0.170600</td>\n",
       "      <td>0</td>\n",
       "      <td>0.358587</td>\n",
       "      <td>0.525351</td>\n",
       "      <td>0.255736</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.063902</td>\n",
       "      <td>0.059416</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.148698</td>\n",
       "      <td>4</td>\n",
       "      <td>0.008207</td>\n",
       "      <td>0</td>\n",
       "      <td>0.207334</td>\n",
       "      <td>0.736463</td>\n",
       "      <td>0.096219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.023381</td>\n",
       "      <td>0.002768</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.161345</td>\n",
       "      <td>0.148266</td>\n",
       "      <td>2896</td>\n",
       "      <td>0.354596</td>\n",
       "      <td>0.152025</td>\n",
       "      <td>0.118075</td>\n",
       "      <td>0</td>\n",
       "      <td>0.158612</td>\n",
       "      <td>0.065728</td>\n",
       "      <td>0.018385</td>\n",
       "      <td>8</td>\n",
       "      <td>0.199617</td>\n",
       "      <td>0.308233</td>\n",
       "      <td>0.016361</td>\n",
       "      <td>15</td>\n",
       "      <td>0.091071</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.652984</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.272008</td>\n",
       "      <td>0.008363</td>\n",
       "      <td>524</td>\n",
       "      <td>0.002644</td>\n",
       "      <td>0.009013</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.119403</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.050882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007729</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.002271</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002310</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008033</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.084683</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002537</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.894090</td>\n",
       "      <td>0.135561</td>\n",
       "      <td>0.911191</td>\n",
       "      <td>0.974539</td>\n",
       "      <td>0.001243</td>\n",
       "      <td>0.766688</td>\n",
       "      <td>1</td>\n",
       "      <td>1.004587</td>\n",
       "      <td>0.893734</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.009968</td>\n",
       "      <td>0.004572</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.008949</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.210060</td>\n",
       "      <td>0.676922</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.238250</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.232120</td>\n",
       "      <td>0.236266</td>\n",
       "      <td>0</td>\n",
       "      <td>0.702280</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.007819</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004345</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2017-04-07</td>\n",
       "      <td>0.936665</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004923</td>\n",
       "      <td>1.000653</td>\n",
       "      <td>0.006151</td>\n",
       "      <td>0.126750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.712795</td>\n",
       "      <td>0.113239</td>\n",
       "      <td>0</td>\n",
       "      <td>0.353630</td>\n",
       "      <td>0.521311</td>\n",
       "      <td>0.223329</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.065261</td>\n",
       "      <td>0.057744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.149723</td>\n",
       "      <td>4</td>\n",
       "      <td>0.008373</td>\n",
       "      <td>0</td>\n",
       "      <td>0.202778</td>\n",
       "      <td>0.720886</td>\n",
       "      <td>0.099804</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.030599</td>\n",
       "      <td>0.002749</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140951</td>\n",
       "      <td>0.143530</td>\n",
       "      <td>2896</td>\n",
       "      <td>0.326757</td>\n",
       "      <td>0.156201</td>\n",
       "      <td>0.118737</td>\n",
       "      <td>0</td>\n",
       "      <td>0.148459</td>\n",
       "      <td>0.093935</td>\n",
       "      <td>0.013035</td>\n",
       "      <td>8</td>\n",
       "      <td>0.151387</td>\n",
       "      <td>0.265026</td>\n",
       "      <td>0.017688</td>\n",
       "      <td>15</td>\n",
       "      <td>0.086805</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647093</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.188970</td>\n",
       "      <td>0.004030</td>\n",
       "      <td>524</td>\n",
       "      <td>0.004193</td>\n",
       "      <td>0.007842</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140611</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.040469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004203</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001864</td>\n",
       "      <td>0.000979</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.009810</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001327</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.081843</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008427</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.902135</td>\n",
       "      <td>0.136333</td>\n",
       "      <td>0.919876</td>\n",
       "      <td>0.975625</td>\n",
       "      <td>0.004561</td>\n",
       "      <td>0.786007</td>\n",
       "      <td>1</td>\n",
       "      <td>1.004118</td>\n",
       "      <td>0.906841</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.003921</td>\n",
       "      <td>0.004654</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.003205</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.184093</td>\n",
       "      <td>0.822281</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.247217</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.243532</td>\n",
       "      <td>0.241885</td>\n",
       "      <td>0</td>\n",
       "      <td>0.707017</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.004333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007495</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005492</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2017-05-28</td>\n",
       "      <td>0.954180</td>\n",
       "      <td>3</td>\n",
       "      <td>0.021655</td>\n",
       "      <td>1.009672</td>\n",
       "      <td>0.006815</td>\n",
       "      <td>0.123977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009423</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.720884</td>\n",
       "      <td>0.060492</td>\n",
       "      <td>0</td>\n",
       "      <td>0.334650</td>\n",
       "      <td>0.524568</td>\n",
       "      <td>0.189424</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.066982</td>\n",
       "      <td>0.056647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.151955</td>\n",
       "      <td>4</td>\n",
       "      <td>0.009355</td>\n",
       "      <td>0</td>\n",
       "      <td>0.206629</td>\n",
       "      <td>0.738044</td>\n",
       "      <td>0.134073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.048367</td>\n",
       "      <td>0.010077</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.112229</td>\n",
       "      <td>0.137014</td>\n",
       "      <td>3166</td>\n",
       "      <td>0.304124</td>\n",
       "      <td>0.153795</td>\n",
       "      <td>0.114534</td>\n",
       "      <td>0</td>\n",
       "      <td>0.139504</td>\n",
       "      <td>0.084757</td>\n",
       "      <td>0.056653</td>\n",
       "      <td>8</td>\n",
       "      <td>0.305883</td>\n",
       "      <td>0.212165</td>\n",
       "      <td>0.063955</td>\n",
       "      <td>15</td>\n",
       "      <td>0.094001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.645819</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.495308</td>\n",
       "      <td>0.006838</td>\n",
       "      <td>702</td>\n",
       "      <td>0.001337</td>\n",
       "      <td>0.006025</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.075868</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.047454</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005419</td>\n",
       "      <td>0.006149</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.009362</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007624</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004056</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.081954</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007327</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.939654</td>\n",
       "      <td>0.134938</td>\n",
       "      <td>0.958699</td>\n",
       "      <td>0.974067</td>\n",
       "      <td>0.011736</td>\n",
       "      <td>0.806840</td>\n",
       "      <td>1</td>\n",
       "      <td>1.009285</td>\n",
       "      <td>0.928719</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001264</td>\n",
       "      <td>0.019176</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000754</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.154837</td>\n",
       "      <td>0.853498</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.239867</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.240768</td>\n",
       "      <td>0.239710</td>\n",
       "      <td>0</td>\n",
       "      <td>0.704843</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.007831</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009227</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006986</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2017-06-13</td>\n",
       "      <td>0.960384</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013683</td>\n",
       "      <td>1.002700</td>\n",
       "      <td>0.001373</td>\n",
       "      <td>0.117169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005531</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.723997</td>\n",
       "      <td>0.166782</td>\n",
       "      <td>0</td>\n",
       "      <td>0.323271</td>\n",
       "      <td>0.530929</td>\n",
       "      <td>0.135586</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.083720</td>\n",
       "      <td>0.049253</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.151219</td>\n",
       "      <td>4</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0</td>\n",
       "      <td>0.208214</td>\n",
       "      <td>0.741813</td>\n",
       "      <td>0.134437</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.030063</td>\n",
       "      <td>0.009667</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.102838</td>\n",
       "      <td>0.129017</td>\n",
       "      <td>2218</td>\n",
       "      <td>0.275055</td>\n",
       "      <td>0.155772</td>\n",
       "      <td>0.120740</td>\n",
       "      <td>0</td>\n",
       "      <td>0.138100</td>\n",
       "      <td>0.048382</td>\n",
       "      <td>0.012498</td>\n",
       "      <td>8</td>\n",
       "      <td>0.273553</td>\n",
       "      <td>0.204300</td>\n",
       "      <td>0.022732</td>\n",
       "      <td>15</td>\n",
       "      <td>0.094854</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.654358</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.508670</td>\n",
       "      <td>0.008183</td>\n",
       "      <td>524</td>\n",
       "      <td>0.008716</td>\n",
       "      <td>0.005271</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.150209</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.031705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005595</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>0.009193</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.004876</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006969</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.060634</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007053</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.913205</td>\n",
       "      <td>0.140058</td>\n",
       "      <td>0.926341</td>\n",
       "      <td>0.975499</td>\n",
       "      <td>0.007571</td>\n",
       "      <td>0.808214</td>\n",
       "      <td>1</td>\n",
       "      <td>1.004514</td>\n",
       "      <td>0.935383</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.002729</td>\n",
       "      <td>0.011720</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.005338</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.153939</td>\n",
       "      <td>0.844667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.240910</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.239400</td>\n",
       "      <td>0.240727</td>\n",
       "      <td>0</td>\n",
       "      <td>0.711546</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.003460</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007206</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006527</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2017-07-16</td>\n",
       "      <td>0.947248</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015193</td>\n",
       "      <td>1.000727</td>\n",
       "      <td>0.007605</td>\n",
       "      <td>0.117325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009312</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.720619</td>\n",
       "      <td>0.143630</td>\n",
       "      <td>0</td>\n",
       "      <td>0.231009</td>\n",
       "      <td>0.529305</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.075900</td>\n",
       "      <td>0.048918</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.154026</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>0</td>\n",
       "      <td>0.205468</td>\n",
       "      <td>0.691986</td>\n",
       "      <td>0.121518</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.054221</td>\n",
       "      <td>0.009484</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.094311</td>\n",
       "      <td>0.129539</td>\n",
       "      <td>2896</td>\n",
       "      <td>0.231110</td>\n",
       "      <td>0.154914</td>\n",
       "      <td>0.095178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.126443</td>\n",
       "      <td>0.039259</td>\n",
       "      <td>0.027897</td>\n",
       "      <td>8</td>\n",
       "      <td>0.233103</td>\n",
       "      <td>0.175655</td>\n",
       "      <td>0.031171</td>\n",
       "      <td>17</td>\n",
       "      <td>0.093915</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650112</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.216507</td>\n",
       "      <td>0.008605</td>\n",
       "      <td>524</td>\n",
       "      <td>0.006821</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.096441</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.032733</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004933</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001833</td>\n",
       "      <td>0.005738</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.007447</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002109</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.062492</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007728</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.921026</td>\n",
       "      <td>0.131620</td>\n",
       "      <td>0.933479</td>\n",
       "      <td>0.978027</td>\n",
       "      <td>0.018200</td>\n",
       "      <td>0.822281</td>\n",
       "      <td>1</td>\n",
       "      <td>1.005735</td>\n",
       "      <td>0.953363</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.009998</td>\n",
       "      <td>0.017598</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.003175</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.120717</td>\n",
       "      <td>0.811199</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.247939</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.244199</td>\n",
       "      <td>0.242325</td>\n",
       "      <td>0</td>\n",
       "      <td>0.705343</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.005053</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006312</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008126</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_ID         S_2       P_2  D_39       B_1       B_2       R_1       S_3  D_41       B_3  D_42  D_43  D_44  B_4      D_45       B_5  R_2      D_46      D_47      D_48  D_49       B_6       B_7  B_8      D_50  D_51       B_9  R_3      D_52       P_3      B_10  D_53       S_5      B_11  S_6  D_54  R_4       S_7      B_12   S_8      D_55      D_56      B_13  R_5      D_58       S_9      B_14  D_59      D_60      D_61      B_15  S_11      D_62  D_63  D_64  D_65  B_16  B_17      B_18  B_19  D_66  B_20  D_68      S_12       R_6  S_13      B_21      D_69  B_22  D_70      D_71  D_72  S_15      B_23  D_73  P_4  D_74  D_75  D_76      B_24  R_7  D_77      B_25      B_26  D_78  D_79  R_8  R_9      S_16  D_80  R_10  R_11      B_27  D_81  D_82      S_17  R_12      B_28  R_13  D_83  R_14  R_15  D_84  R_16  B_29  B_30  S_18  D_86  D_87  R_17  R_18  D_88  B_31      S_19  R_19  B_32  S_20  R_20  R_21  B_33  D_89  R_22  R_23  D_91  D_92  D_93  D_94  R_24  \\\n",
       "0  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-03-09  0.938469     0  0.008724  1.006838  0.009228  0.124035   0.0  0.004709   NaN   NaN     0    6  0.708906  0.170600    0  0.358587  0.525351  0.255736    -1  0.063902  0.059416  0.0  0.148698     4  0.008207    0  0.207334  0.736463  0.096219   NaN  0.023381  0.002768    0   1.0    0  0.161345  0.148266  2896  0.354596  0.152025  0.118075    0  0.158612  0.065728  0.018385     8  0.199617  0.308233  0.016361    15  0.091071     0     0     0     0   NaN  0.652984     0    -1     0     6  0.272008  0.008363   524  0.002644  0.009013     0     0  0.119403     0     4  0.050882   NaN  0.0     1     1   NaN  0.004327  0.0   NaN  0.007729  0.000272     0     0    0   -1  0.002271     0     0     0  0.002310     0     1  0.008033   1.0  0.084683     0     0   0.0     0     0     0   NaN     0     0     0    -1     0     0   NaN     1  0.002537     0     0     0     0     0     1     0     0     0     3     1     0     0     0   \n",
       "1  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-04-07  0.936665     0  0.004923  1.000653  0.006151  0.126750   0.0  0.002714   NaN   NaN     0    5  0.712795  0.113239    0  0.353630  0.521311  0.223329    -1  0.065261  0.057744  0.0  0.149723     4  0.008373    0  0.202778  0.720886  0.099804   NaN  0.030599  0.002749    0   1.0    0  0.140951  0.143530  2896  0.326757  0.156201  0.118737    0  0.148459  0.093935  0.013035     8  0.151387  0.265026  0.017688    15  0.086805     0     0     0     0   NaN  0.647093     0    -1     0     6  0.188970  0.004030   524  0.004193  0.007842     0     0  0.140611     0     4  0.040469   NaN  0.0     1     1   NaN  0.004203  0.0   NaN  0.001864  0.000979     0     0    0   -1  0.009810     0     0     0  0.001327     0     1  0.000760   1.0  0.081843     0     0   0.0     0     0     0   NaN     0     0     0    -1     0     0   NaN     1  0.008427     0     0     0     0     0     1     0     0     0     3     1     0     0     0   \n",
       "2  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-05-28  0.954180     3  0.021655  1.009672  0.006815  0.123977   0.0  0.009423   NaN   NaN     0    5  0.720884  0.060492    0  0.334650  0.524568  0.189424    -1  0.066982  0.056647  0.0  0.151955     4  0.009355    0  0.206629  0.738044  0.134073   NaN  0.048367  0.010077    0   1.0    0  0.112229  0.137014  3166  0.304124  0.153795  0.114534    0  0.139504  0.084757  0.056653     8  0.305883  0.212165  0.063955    15  0.094001     0     0     0     0   NaN  0.645819     0    -1     0     6  0.495308  0.006838   702  0.001337  0.006025     0     0  0.075868     0     4  0.047454   NaN  0.0     1     1   NaN  0.001782  0.0   NaN  0.005419  0.006149     0     0    0   -1  0.009362     0     0     0  0.007624     0     1  0.004056   1.0  0.081954     0     0   0.0     0     0     0   NaN     0     0     0    -1     0     0   NaN     1  0.007327     0     0     0     0     0     1     0     0     0     3     1     0     0     0   \n",
       "3  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-06-13  0.960384     0  0.013683  1.002700  0.001373  0.117169   0.0  0.005531   NaN   NaN     0    4  0.723997  0.166782    0  0.323271  0.530929  0.135586    -1  0.083720  0.049253  0.0  0.151219     4  0.006782    0  0.208214  0.741813  0.134437   NaN  0.030063  0.009667    0   1.0    0  0.102838  0.129017  2218  0.275055  0.155772  0.120740    0  0.138100  0.048382  0.012498     8  0.273553  0.204300  0.022732    15  0.094854     0     0     0     0   NaN  0.654358     0    -1     0     6  0.508670  0.008183   524  0.008716  0.005271     0     0  0.150209     0     5  0.031705   NaN  0.0     1     1   NaN  0.005595  0.0   NaN  0.000646  0.009193     0     0    0   -1  0.004876     0     0     0  0.000034     0     1  0.006969   1.0  0.060634     0     0   0.0     0     0     0   NaN     0     0     0    -1     0     0   NaN     1  0.007053     0     0     0     0     0     1     0     0     0     3     1     0     0     0   \n",
       "4  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-07-16  0.947248     0  0.015193  1.000727  0.007605  0.117325   0.0  0.009312   NaN   NaN     0    3  0.720619  0.143630    0  0.231009  0.529305       NaN    -1  0.075900  0.048918  0.0  0.154026     4  0.000519    0  0.205468  0.691986  0.121518   NaN  0.054221  0.009484    0   1.0    0  0.094311  0.129539  2896  0.231110  0.154914  0.095178    0  0.126443  0.039259  0.027897     8  0.233103  0.175655  0.031171    17  0.093915     0     0     0     0   NaN  0.650112     0    -1     0     6  0.216507  0.008605   524  0.006821  0.000152     0     0  0.096441     0     4  0.032733   NaN  0.0     1     1   NaN  0.004933  0.0   NaN  0.001833  0.005738     0     0    0   -1  0.007447     0     0     0  0.002109     0     1  0.001770   1.0  0.062492     0     0   0.0     0     0     0   NaN     0     0     0    -1     0     0   NaN     1  0.007728     0     0     0     0     0     1     0     0     0     3     1     0     0     0   \n",
       "\n",
       "   R_25  D_96      S_22      S_23      S_24      S_25      S_26     D_102  D_103     D_104     D_105  D_106  D_107      B_36      B_37  R_26      R_27  B_38  D_108  D_109  D_110  D_111  B_39  D_112      B_40      S_27  D_113  D_114     D_115  D_116  D_117     D_118     D_119  D_120     D_121  D_122  D_123  D_124  D_125  D_126  D_127     D_128  D_129  B_41  B_42  D_130  D_131  D_132     D_133  R_28  D_134  D_135  D_136  D_137  D_138  D_139  D_140  D_141  D_142  D_143     D_144  D_145  \n",
       "0     0     0  0.894090  0.135561  0.911191  0.974539  0.001243  0.766688      1  1.004587  0.893734     -1      2  0.009968  0.004572    -1  1.008949     2     -1      0    NaN     -1   NaN    1.0  0.210060  0.676922      0      1  0.238250      0      5  0.232120  0.236266      0  0.702280      3      0     16      0      2      1  1.007819      1     0   NaN    0.0    0.0    NaN  0.004345     0    NaN     -1     -1     -1     -1      0      0    0.0    NaN      0  0.000610      0  \n",
       "1     0     0  0.902135  0.136333  0.919876  0.975625  0.004561  0.786007      1  1.004118  0.906841     -1      2  0.003921  0.004654    -1  1.003205     2     -1      0    NaN     -1   NaN    1.0  0.184093  0.822281      0      1  0.247217      0      5  0.243532  0.241885      0  0.707017      3      0     16      0      2      1  1.004333      1     0   NaN    0.0    0.0    NaN  0.007495     0    NaN     -1     -1     -1     -1      0      0    0.0    NaN      0  0.005492      0  \n",
       "2     0     0  0.939654  0.134938  0.958699  0.974067  0.011736  0.806840      1  1.009285  0.928719     -1      2  0.001264  0.019176    -1  1.000754     2     -1      0    NaN     -1   NaN    1.0  0.154837  0.853498      0      1  0.239867      0      5  0.240768  0.239710      0  0.704843      3      0     16      0      2      1  1.007831      1     0   NaN    0.0    0.0    NaN  0.009227     0    NaN     -1     -1     -1     -1      0      0    0.0    NaN      0  0.006986      0  \n",
       "3     0     0  0.913205  0.140058  0.926341  0.975499  0.007571  0.808214      1  1.004514  0.935383     -1      2  0.002729  0.011720    -1  1.005338     2     -1      0    NaN     -1   NaN    1.0  0.153939  0.844667      0      1  0.240910      0      5  0.239400  0.240727      0  0.711546      3      0     16      0      2      1  1.003460      1     0   NaN    0.0    0.0    NaN  0.007206     0    NaN     -1     -1     -1     -1      0      0    0.0    NaN      0  0.006527      0  \n",
       "4     0     0  0.921026  0.131620  0.933479  0.978027  0.018200  0.822281      1  1.005735  0.953363     -1      2  0.009998  0.017598    -1  1.003175     2     -1      0    NaN     -1   NaN    1.0  0.120717  0.811199      0      1  0.247939      0      5  0.244199  0.242325      0  0.705343      3      0     16      0      2      1  1.005053      1     0   NaN    0.0    0.0    NaN  0.006312     0    NaN     -1     -1     -1     -1      0      0    0.0    NaN      0  0.008126      0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7454b618",
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
